import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import platform
import re
import os

# --- ã€æ ¸å¿ƒä¿®æ­£ã€‘è¨­å®š Matplotlib ç›´æ¥ä½¿ç”¨æˆ‘å€‘æä¾›çš„å­—é«”æª”æ¡ˆ ---
# å°‡å­—é«”æª”æ¡ˆåç¨±æ›´æ–°ç‚º .ttf
FONT_FILE = 'NotoSansTC.ttf'

if os.path.exists(FONT_FILE):
    # å¦‚æœå­˜åœ¨ï¼Œå°±è¨­å®šç‚ºé è¨­å­—é«”
    plt.rcParams['font.family'] = fm.FontProperties(fname=FONT_FILE).get_name()
    plt.rcParams['axes.unicode_minus'] = False
else:
    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå‰‡å˜—è©¦å‚™ç”¨æ–¹æ¡ˆ
    try:
        if platform.system() == 'Windows':
            plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
        elif platform.system() == 'Darwin':
            plt.rcParams['font.sans-serif'] = ['PingFang TC']
        else:
            plt.rcParams['font.sans-serif'] = ['Noto Sans CJK JP']
        plt.rcParams['axes.unicode_minus'] = False
    except Exception as e:
        st.warning(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°æŒ‡å®šçš„ {FONT_FILE} å­—é«”æª”æ¡ˆï¼Œä¸”å‚™ç”¨ç³»çµ±å­—é«”è¨­å®šå¤±æ•—ã€‚åœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚")

# --- æ–‡å­—è™•ç†å‡½å¼ ---
def format_and_highlight_text(text, keywords):
    text_str = str(text).strip()
    if not text_str: return ""
    list_marker_pattern = re.compile(r'(\s*[ï¼ˆ(]?\d+[.)ï¼‰]\s*|\s*[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*)')
    parts = list_marker_pattern.split(text_str)
    html_output = f'<p style="margin:0; padding:0;">{parts[0]}'
    for i in range(1, len(parts), 2):
        if i + 1 < len(parts):
            marker = parts[i].strip(); content = parts[i+1].strip()
            html_output += f'<div style="margin-left: 2em; text-indent: -2em; padding-top: 5px;">{marker} {content}</div>'
    html_output += '</p>'
    if keywords:
        pattern = '|'.join([re.escape(keyword) for keyword in keywords])
        html_output = re.sub(
            pattern, 
            lambda match: f'<span style="background-color: yellow;">{match.group(0)}</span>', 
            html_output, 
            flags=re.IGNORECASE
        )
    return html_output

# --- æ ¸å¿ƒåŠŸèƒ½å‡½å¼ (è™•ç†è³‡æ–™) ---
@st.cache_data
def process_dataframe(df):
    text_columns_for_features = [
        'å­¸æ ¡é—œæ³¨äº‹é …', 'å­¸ç¿’å’Œæ•™å­¸ç­–ç•¥', 'å°å­¸æ•™è‚²èª²ç¨‹æ›´æ–°é‡é»çš„ç™¼å±•', 'å…±é€šèƒ½åŠ›çš„åŸ¹é¤Š', 'æ­£ç¢ºåƒ¹å€¼è§€ã€æ…‹åº¦å’Œè¡Œç‚ºçš„åŸ¹é¤Š',
        'å…¨æ ¡åƒèˆ‡ç…§é¡§å­¸ç”Ÿçš„å¤šæ¨£æ€§', 'å…¨æ ¡åƒèˆ‡æ¨¡å¼èåˆæ•™è‚²', 'éè¯èªå­¸ç”Ÿçš„æ•™è‚²æ”¯æ´', 'èª²ç¨‹å‰ªè£åŠèª¿é©æªæ–½',
        'å®¶æ ¡åˆä½œ', 'æ ¡é¢¨', 'å­¸æ ¡ç™¼å±•è¨ˆåŠƒ', 'æ•™å¸«å°ˆæ¥­åŸ¹è¨“åŠç™¼å±•', 'å…¶ä»–æœªä¾†ç™¼å±•', 'è¾¦å­¸å®—æ—¨', 'å…¨æ–¹ä½å­¸ç¿’', 'ç‰¹åˆ¥å®¤', 'å…¶ä»–å­¸æ ¡è¨­æ–½'
    ]
    existing_feature_columns = [col for col in text_columns_for_features if col in df.columns]
    df['features_text'] = df[existing_feature_columns].fillna('').astype(str).agg(' '.join, axis=1)
    percentage_cols = [
        'å·²æ¥å—å¸«è³‡åŸ¹è¨“(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 'å­¸å£«(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 'ç¢©å£«ã€åšå£«æˆ–ä»¥ä¸Š (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 'ç‰¹æ®Šæ•™è‚²åŸ¹è¨“ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)',
        '0-4å¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', '5-9å¹´è³‡(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', '10å¹´æˆ–ä»¥ä¸Šå¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)'
    ]
    for col in percentage_cols:
        if col in df.columns:
            s = pd.to_numeric(df[col].astype(str).str.replace('%', '', regex=False), errors='coerce').fillna(0)
            if not s.empty and s.max() > 0 and s.max() <= 1: s = s * 100
            df[col] = s.round(1)
    numeric_cols = [
        'æ ¸å‡†ç·¨åˆ¶æ•™å¸«è·ä½æ•¸ç›®', 'å…¨æ ¡æ•™å¸«ç¸½äººæ•¸', 'ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸', 'ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸',
        'äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸', 'äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸'
    ]
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
    yes_no_cols = {
        'å°ä¸€ä¸Šå­¸æœŸä»¥å¤šå…ƒåŒ–çš„é€²å±•æ€§è©•ä¼°ä»£æ›¿æ¸¬é©—åŠè€ƒè©¦': 'p1_no_exam_assessment',
        'é¿å…ç·Šæ¥åœ¨é•·å‡æœŸå¾Œå®‰æ’æ¸¬è€ƒï¼Œè®“å­¸ç”Ÿåœ¨å‡æœŸæœ‰å……åˆ†çš„ä¼‘æ¯': 'avoid_holiday_exams',
        'æŒ‰æ ¡æƒ…éˆæ´»ç·¨æ’æ™‚é–“è¡¨ï¼Œç›¡é‡åœ¨ä¸‹åˆå®‰æ’å°ä¿®æ™‚æ®µï¼Œè®“å­¸ç”Ÿèƒ½åœ¨æ•™å¸«æŒ‡å°ä¸‹å®Œæˆéƒ¨åˆ†å®¶èª²': 'afternoon_tutorial'
    }
    for col, new_name in yes_no_cols.items():
        if col in df.columns:
            df[new_name] = df[col].apply(lambda x: 'æ˜¯' if str(x).strip() in ['æœ‰', 'Yes'] else 'å¦')
    return df

# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä»‹é¢ ---
st.set_page_config(page_title="å­¸æ ¡é¸æ ¡å™¨", layout="centered")
st.title('ğŸ« å­¸æ ¡é¸æ ¡å™¨')
st.write("è«‹å…ˆä¸Šå‚³æ‚¨çš„å­¸æ ¡è³‡æ–™æª”æ¡ˆï¼Œç„¶å¾Œä½¿ç”¨ä¸‹æ–¹çš„ç¯©é¸å™¨ä¾†å°‹æ‰¾å¿ƒå„€çš„å­¸æ ¡ã€‚")

uploaded_file = st.file_uploader("**è«‹ä¸Šå‚³æ‚¨çš„å­¸æ ¡è³‡æ–™æª”æ¡ˆ (Excel æˆ– CSV)**", type=['csv', 'xlsx'])

if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith('.csv'): dataframe = pd.read_csv(uploaded_file, engine='python')
        else: dataframe = pd.read_excel(uploaded_file, engine='openpyxl')
        
        processed_df = process_dataframe(dataframe)
        st.success(f'æˆåŠŸè®€å– {len(processed_df)} ç­†å­¸æ ¡è³‡æ–™ï¼')
        filtered_df = processed_df.copy()
        all_selected_keywords_for_highlight = []
        with st.expander("ğŸ“ æŒ‰å­¸æ ¡åç¨±æœå°‹", expanded=True):
            search_keyword = st.text_input("**è¼¸å…¥å­¸æ ¡åç¨±é—œéµå­—ï¼š**")
            if search_keyword: filtered_df = filtered_df[filtered_df['å­¸æ ¡åç¨±'].str.contains(search_keyword, case=False, na=False)]
        with st.expander("ğŸ“ æŒ‰åœ°å€åŠæ ¡ç¶²æœå°‹", expanded=True):
            col1, col2 = st.columns(2)
            with col1:
                all_districts = sorted(processed_df['åœ°å€'].dropna().unique()); selected_districts = st.multiselect("**é¸æ“‡åœ°å€ (å¯å¤šé¸)**", options=all_districts)
                if selected_districts: filtered_df = filtered_df[filtered_df['åœ°å€'].isin(selected_districts)]
            with col2:
                if selected_districts: available_nets = sorted(processed_df[processed_df['åœ°å€'].isin(selected_districts)]['æ ¡ç¶²'].dropna().unique())
                else: available_nets = sorted(processed_df['æ ¡ç¶²'].dropna().unique())
                selected_nets = st.multiselect("**é¸æ“‡æ ¡ç¶² (å¯å¤šé¸)**", options=available_nets)
                if selected_nets: filtered_df = filtered_df[filtered_df['æ ¡ç¶²'].isin(selected_nets)]
        with st.expander("ğŸŒŸ æŒ‰è¾¦å­¸ç‰¹è‰²æœå°‹", expanded=False):
            feature_mapping = {
                "ã€æ•™å­¸æ¨¡å¼èˆ‡é‡é»ã€‘": {"è‡ªä¸»å­¸ç¿’åŠæ¢ç©¶": ['è‡ªä¸»å­¸ç¿’', 'æ¢ç©¶'], "STEAM": ['STEAM', 'å‰µå®¢'], "é›»å­å­¸ç¿’": ['é›»å­å­¸ç¿’', 'e-learning'], "é–±è®€": ['é–±è®€'], "è³‡å„ªæ•™è‚²": ['è³‡å„ª'], "å°ˆé¡Œç ”ç¿’": ['å°ˆé¡Œç ”ç¿’'], "è·¨èª²ç¨‹å­¸ç¿’": ['è·¨èª²ç¨‹'], "å…©æ–‡ä¸‰èª": ['å…©æ–‡ä¸‰èª'], "è‹±æ–‡æ•™è‚²": ['è‹±æ–‡'], "å®¶æ ¡åˆä½œ": ['å®¶æ ¡åˆä½œ'], "å¢ƒå¤–äº¤æµ": ['å¢ƒå¤–äº¤æµ'], "è—è¡“": ['è—è¡“'], "é«”è‚²": ['é«”è‚²']},
                "ã€åƒ¹å€¼è§€èˆ‡å“å¾·ã€‘": {"ä¸­è¯æ–‡åŒ–æ•™è‚²": ['ä¸­è¯æ–‡åŒ–'], "æ­£å‘ã€åƒ¹å€¼è§€ã€ç”Ÿå‘½æ•™è‚²": ['æ­£å‘', 'åƒ¹å€¼è§€', 'ç”Ÿå‘½æ•™è‚²'], "åœ‹æ°‘æ•™è‚²ã€åœ‹å®‰æ•™è‚²": ['åœ‹æ°‘', 'åœ‹å®‰'], "æœå‹™æ•™è‚²": ['æœå‹™'], "é—œæ„›åŠç²¾ç¥å¥åº·": ['é—œæ„›', 'å¥åº·']},
                "ã€å­¸ç”Ÿæ”¯æ´èˆ‡ç™¼å±•ã€‘": {"å…¨äººç™¼å±•": ['å…¨äººç™¼å±•', 'å¤šå…ƒç™¼å±•'], "ç”Ÿæ¶¯è¦åŠƒã€å•Ÿç™¼æ½›èƒ½": ['ç”Ÿæ¶¯è¦åŠƒ', 'æ½›èƒ½'], "æ‹”å°–è£œåº•ã€ç…§é¡§å·®ç•°": ['æ‹”å°–è£œåº•', 'å€‹åˆ¥å·®ç•°'], "èåˆæ•™è‚²": ['èåˆæ•™è‚²']}
            }
            col1, col2, col3 = st.columns(3); all_selected_options = []
            with col1: selected1 = st.multiselect("æ•™å­¸æ¨¡å¼èˆ‡é‡é»", options=list(feature_mapping["ã€æ•™å­¸æ¨¡å¼èˆ‡é‡é»ã€‘"].keys())); all_selected_options.extend(selected1)
            with col2: selected2 = st.multiselect("åƒ¹å€¼è§€èˆ‡å“å¾·", options=list(feature_mapping["ã€åƒ¹å€¼è§€èˆ‡å“å¾·ã€‘"].keys())); all_selected_options.extend(selected2)
            with col3: selected3 = st.multiselect("å­¸ç”Ÿæ”¯æ´èˆ‡ç™¼å±•", options=list(feature_mapping["ã€å­¸ç”Ÿæ”¯æ´èˆ‡ç™¼å±•ã€‘"].keys())); all_selected_options.extend(selected3)
            if all_selected_options:
                for option in all_selected_options:
                    search_terms = [];
                    for category in feature_mapping.values():
                        if option in category: search_terms = category[option]; all_selected_keywords_for_highlight.extend(search_terms); break
                    if search_terms:
                        regex_pattern = '|'.join([re.escape(term) for term in search_terms])
                        filtered_df = filtered_df[filtered_df['features_text'].str.contains(regex_pattern, case=False, na=False, regex=True)]
        with st.expander("ğŸ“ æŒ‰å¸«è³‡æ¢ä»¶æœå°‹", expanded=False):
            st.write("é€éæ»‘æ¡¿è¨­å®šæ‚¨å°å¸«è³‡çš„**æœ€ä½**è¦æ±‚ï¼š")
            slider_options = {'å·²æ¥å—å¸«è³‡åŸ¹è¨“(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'å¸«è³‡åŸ¹è¨“æ¯”ä¾‹ (%)', 'å­¸å£«(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'å­¸å£«å­¸æ­·æ¯”ä¾‹ (%)', 'ç¢©å£«ã€åšå£«æˆ–ä»¥ä¸Š (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'ç¢©å£«æˆ–ä»¥ä¸Šå­¸æ­·æ¯”ä¾‹ (%)', 'ç‰¹æ®Šæ•™è‚²åŸ¹è¨“ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'ç‰¹æ®Šæ•™è‚²åŸ¹è¨“æ¯”ä¾‹ (%)', '0-4å¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': '0-4å¹´è³‡æ¯”ä¾‹ (%)', '5-9å¹´è³‡(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': '5-9å¹´è³‡æ¯”ä¾‹ (%)', '10å¹´æˆ–ä»¥ä¸Šå¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': '10å¹´ä»¥ä¸Šå¹´è³‡æ¯”ä¾‹ (%)'}
            for col_name, slider_label in slider_options.items():
                if col_name in filtered_df.columns:
                    min_val = st.slider(slider_label, 0, 100, 0, 5, key=col_name)
                    if min_val > 0: filtered_df = filtered_df[filtered_df[col_name] >= min_val]
        with st.expander("ğŸ“š æŒ‰èª²æ¥­å®‰æ’æœå°‹", expanded=False):
            st.write("é¸æ“‡æ‚¨åå¥½çš„èª²æ¥­èˆ‡è©•ä¼°æ–¹å¼ï¼š")
            st.markdown("**è©•ä¼°æ¬¡æ•¸**"); col1, col2 = st.columns(2)
            with col1:
                max_p1_tests = st.selectbox('å°ä¸€å…¨å¹´æœ€å¤šæ¸¬é©—æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3, 4], index=0, key='p1_test')
                if max_p1_tests != 'ä»»ä½•æ¬¡æ•¸': filtered_df = filtered_df[filtered_df['ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸'] <= int(max_p1_tests)]
                max_p2_6_tests = st.selectbox('äºŒè‡³å…­å¹´ç´šæœ€å¤šæ¸¬é©—æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3, 4], index=0, key='p2-6_test')
                if max_p2_6_tests != 'ä»»ä½•æ¬¡æ•¸': filtered_df = filtered_df[filtered_df['äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸'] <= int(max_p2_6_tests)]
            with col2:
                max_p1_exams = st.selectbox('å°ä¸€å…¨å¹´æœ€å¤šè€ƒè©¦æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3], index=0, key='p1_exam')
                if max_p1_exams != 'ä»»ä½•æ¬¡æ•¸': filtered_df = filtered_df[filtered_df['ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸'] <= int(max_p1_exams)]
                max_p2_6_exams = st.selectbox('äºŒè‡³å…­å¹´ç´šæœ€å¤šè€ƒè©¦æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3, 4], index=0, key='p2-6_exam')
                if max_p2_6_exams != 'ä»»ä½•æ¬¡æ•¸': filtered_df = filtered_df[filtered_df['äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸'] <= int(max_p2_6_exams)]
            st.markdown("**å…¶ä»–å®‰æ’**"); p1_no_exam = st.radio("å°ä¸€ä¸Šå­¸æœŸä»¥å¤šå…ƒåŒ–è©•ä¼°ä»£æ›¿æ¸¬è€ƒï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True)
            if p1_no_exam != 'ä¸é™' and 'p1_no_exam_assessment' in filtered_df.columns: filtered_df = filtered_df[filtered_df['p1_no_exam_assessment'] == p1_no_exam]
            avoid_holiday = st.radio("é¿å…é•·å‡å¾Œæ¸¬è€ƒï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True)
            if avoid_holiday != 'ä¸é™' and 'avoid_holiday_exams' in filtered_df.columns: filtered_df = filtered_df[filtered_df['avoid_holiday_exams'] == avoid_holiday]
            afternoon_tut = st.radio("è¨­ä¸‹åˆå°ä¿®æ™‚æ®µï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True)
            if afternoon_tut != 'ä¸é™' and 'afternoon_tutorial' in filtered_df.columns: filtered_df = filtered_df[filtered_df['afternoon_tutorial'] == afternoon_tut]
        st.markdown("---"); st.header(f"æœå°‹çµæœ"); st.info(f"ç¶œåˆæ‰€æœ‰æ¢ä»¶ï¼Œå…±æ‰¾åˆ° {len(filtered_df)} æ‰€å­¸æ ¡ã€‚")
        for index, school in filtered_df.iterrows():
            with st.expander(f"**{school['å­¸æ ¡åç¨±']}** ({school.get('åœ°å€', 'N/A')})"):
                st.markdown("#### ğŸ« å­¸æ ¡è¨­æ–½è©³æƒ…")
                facility_counts = (f"ğŸ« èª²å®¤: {school.get('èª²å®¤æ•¸ç›®', 'N/A')} | ğŸ›ï¸ ç¦®å ‚: {school.get('ç¦®å ‚æ•¸ç›®', 'N/A')} | ğŸ¤¸ æ“å ´: {school.get('æ“å ´æ•¸ç›®', 'N/A')} | ğŸ“š åœ–æ›¸é¤¨: {school.get('åœ–æ›¸é¤¨æ•¸ç›®', 'N/A')}")
                st.markdown(facility_counts)
                other_facilities = {"ç‰¹åˆ¥å®¤": "ç‰¹åˆ¥å®¤", "æ”¯æ´æœ‰ç‰¹æ®Šæ•™è‚²éœ€è¦å­¸ç”Ÿçš„è¨­æ–½": "SEN æ”¯æ´è¨­æ–½", "å…¶ä»–å­¸æ ¡è¨­æ–½": "å…¶ä»–è¨­æ–½"}
                for column_name, display_title in other_facilities.items():
                    detail_value = school.get(column_name, '');
                    if pd.notna(detail_value) and str(detail_value).strip() not in ['', '-']: st.write(f"**{display_title}:** {detail_value}")
                st.markdown("---"); total_teachers = school.get('å…¨æ ¡æ•™å¸«ç¸½äººæ•¸', 0); approved_teachers = school.get('æ ¸å‡†ç·¨åˆ¶æ•™å¸«è·ä½æ•¸ç›®', 0); diff = total_teachers - approved_teachers
                st.markdown("#### ğŸ§‘â€ğŸ« å¸«è³‡åœ˜éšŠæ¦‚è¦½"); col1, col2 = st.columns(2)
                with col1: st.metric("æ ¸å‡†ç·¨åˆ¶æ•™å¸«è·ä½", f"{approved_teachers} äºº")
                with col2:
                    if diff >= 0: st.metric("å…¨æ ¡æ•™å¸«ç¸½äººæ•¸", f"{total_teachers} äºº", f"+{diff}", delta_color="normal")
                    else: st.metric("å…¨æ ¡æ•™å¸«ç¸½äººæ•¸", f"{total_teachers} äºº", f"{diff}", delta_color="inverse")
                st.markdown("#### ğŸ“Š å¸«è³‡æ¯”ä¾‹åˆ†ä½ˆåœ–"); pie_col1, pie_col2 = st.columns(2)
                with pie_col1:
                    st.markdown("**å­¸æ­·åˆ†ä½ˆ**"); edu_labels = ['å­¸å£«', 'ç¢©å£«æˆ–ä»¥ä¸Š']; edu_sizes = [school.get('å­¸å£«(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0), school.get('ç¢©å£«ã€åšå£«æˆ–ä»¥ä¸Š (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0)]
                    if sum(edu_sizes) > 0: fig1, ax1 = plt.subplots(figsize=(3, 3)); ax1.pie(edu_sizes, labels=edu_labels, autopct='%1.1f%%', startangle=90, colors=['#66b3ff','#99ff99']); ax1.axis('equal'); st.pyplot(fig1)
                    else: st.text("ç„¡ç›¸é—œæ•¸æ“š")
                with pie_col2:
                    st.markdown("**å¹´è³‡åˆ†ä½ˆ**"); exp_labels = ['0-4å¹´', '5-9å¹´', '10å¹´ä»¥ä¸Š']; exp_sizes = [school.get('0-4å¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0), school.get('5-9å¹´è³‡(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0), school.get('10å¹´æˆ–ä»¥ä¸Šå¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0)]
                    if sum(exp_sizes) > 0: fig2, ax2 = plt.subplots(figsize=(3, 3)); ax2.pie(exp_sizes, labels=exp_labels, autopct='%1.1f%%', startangle=90, colors=['#ffcc99','#c2c2f0','#ffb3e6']); ax2.axis('equal'); st.pyplot(fig2)
                    else: st.text("ç„¡ç›¸é—œæ•¸æ“š")
                st.markdown("---"); st.markdown("#### ğŸ“š èª²æ¥­èˆ‡è©•ä¼°å®‰æ’")
                homework_details = {"å°ä¸€æ¸¬é©—/è€ƒè©¦æ¬¡æ•¸": f"{school.get('ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸', 'N/A')} / {school.get('ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸', 'N/A')}", "é«˜å¹´ç´šæ¸¬é©—/è€ƒè©¦æ¬¡æ•¸": f"{school.get('äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸', 'N/A')} / {school.get('äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸', 'N/A')}", "å°ä¸€å…è©¦è©•ä¼°": school.get('p1_no_exam_assessment', 'N/A'), "å¤šå…ƒå­¸ç¿’è©•ä¼°": school.get('å¤šå…ƒå­¸ç¿’è©•ä¼°', 'æœªæä¾›'), "é¿å…é•·å‡å¾Œæ¸¬è€ƒ": school.get('avoid_holiday_exams', 'N/A'), "ä¸‹åˆå°ä¿®æ™‚æ®µ": school.get('afternoon_tutorial', 'N/A')}
                for title, value in homework_details.items():
                    if pd.notna(value) and str(value).strip() != '': st.write(f"**{title}:** {value}")
                st.markdown("---"); st.markdown("#### âœ¨ è¾¦å­¸ç‰¹è‰²èˆ‡ç™¼å±•è¨ˆåŠƒ")
                feature_text_map = {"å­¸æ ¡é—œæ³¨äº‹é …": "å­¸æ ¡é—œæ³¨äº‹é …", "å­¸ç¿’å’Œæ•™å­¸ç­–ç•¥": "å­¸ç¿’å’Œæ•™å­¸ç­–ç•¥", "å°å­¸æ•™è‚²èª²ç¨‹æ›´æ–°é‡é»çš„ç™¼å±•": "èª²ç¨‹æ›´æ–°é‡é»", "å…±é€šèƒ½åŠ›çš„åŸ¹é¤Š": "å…±é€šèƒ½åŠ›åŸ¹é¤Š", "æ­£ç¢ºåƒ¹å€¼è§€ã€æ…‹åº¦å’Œè¡Œç‚ºçš„åŸ¹é¤Š": "åƒ¹å€¼è§€åŸ¹é¤Š", "å…¨æ ¡åƒèˆ‡ç…§é¡§å­¸ç”Ÿçš„å¤šæ¨£æ€§": "ç…§é¡§å­¸ç”Ÿå¤šæ¨£æ€§", "å…¨æ ¡åƒèˆ‡æ¨¡å¼èåˆæ•™è‚²": "èåˆæ•™è‚²æ¨¡å¼", "éè¯èªå­¸ç”Ÿçš„æ•™è‚²æ”¯æ´": "éè¯èªå­¸ç”Ÿæ”¯æ´", "èª²ç¨‹å‰ªè£åŠèª¿é©æªæ–½": "èª²ç¨‹å‰ªè£èª¿é©", "å®¶æ ¡åˆä½œ": "å®¶æ ¡åˆä½œ", "æ ¡é¢¨": "æ ¡é¢¨", "å­¸æ ¡ç™¼å±•è¨ˆåŠƒ": "å­¸æ ¡ç™¼å±•è¨ˆåŠƒ", "æ•™å¸«å°ˆæ¥­åŸ¹è¨“åŠç™¼å±•": "æ•™å¸«å°ˆæ¥­ç™¼å±•", "å…¶ä»–æœªä¾†ç™¼å±•": "å…¶ä»–æœªä¾†ç™¼å±•"}
                for column_name, display_title in feature_text_map.items():
                    detail_value = school.get(column_name, '');
                    if pd.notna(detail_value) and str(detail_value).strip() not in ['', '-']:
                        st.write(f"**{display_title}:**"); formatted_content = format_and_highlight_text(detail_value, all_selected_keywords_for_highlight); st.markdown(formatted_content, unsafe_allow_html=True)
    except Exception as e:
        st.error(f"æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{e}")
else:
    st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆï¼Œç¯©é¸å™¨å°‡æœƒåœ¨æ­¤è™•é¡¯ç¤ºã€‚")
