import streamlit as st
import pandas as pd
import plotly.express as px
import re
import os
import requests
from bs4 import BeautifulSoup

# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä»‹é¢ ---
st.set_page_config(page_title="ã€Œ01æ•™è‚²ã€å°å­¸æ¦‚è¦½æœå°‹å™¨", layout="centered")
st.title('ã€Œ01æ•™è‚²ã€å°å­¸æ¦‚è¦½æœå°‹å™¨')
st.write("è«‹ä¸Šå‚³åŒ…å«å­¸æ ¡è³‡æ–™çš„æª”æ¡ˆã€‚å»ºè­°ä½¿ç”¨æœ‰ã€Œå­¸æ ¡è³‡æ–™ã€å’Œã€Œç›¸é—œæ–‡ç« ã€å…©å€‹å·¥ä½œè¡¨çš„ Excel æª”æ¡ˆã€‚")

# --- åˆå§‹åŒ– Session State ---
if 'page' not in st.session_state:
    st.session_state.page = 0
if 'active_filters_cache' not in st.session_state:
    st.session_state.active_filters_cache = None

# --- ç²å–æ–‡ç«  Meta Data çš„å¿«å–å‡½å¼ ---
@st.cache_data(ttl=3600)
def get_article_metadata(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        og_image_tag = soup.find('meta', property='og:image')
        
        if og_image_tag and og_image_tag.get('content'):
            return og_image_tag['content']
            
    except requests.RequestException:
        return None
    return None

# --- æ–‡å­—è™•ç†å‡½å¼ ---
def format_and_highlight_text(text, keywords):
    text_str = str(text).strip()
    if not text_str: return ""
    list_marker_pattern = re.compile(r'(\s*[ï¼ˆ(]?\d+[.)ï¼‰]\s*|\s*[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*)')
    parts = list_marker_pattern.split(text_str)
    html_output = f'<p style="margin:0; padding:0;">{parts[0]}'
    for i in range(1, len(parts), 2):
        if i + 1 < len(parts):
            marker = parts[i].strip(); content = parts[i+1].strip()
            html_output += f'<div style="margin-left: 2em; text-indent: -2em; padding-top: 5px;">{marker} {content}</div>'
    html_output += '</p>'
    if keywords:
        pattern = '|'.join([re.escape(keyword) for keyword in keywords])
        html_output = re.sub(
            pattern,
            lambda match: f'<span style="background-color: yellow;">{match.group(0)}</span>',
            html_output,
            flags=re.IGNORECASE
        )
    return html_output

# --- æ ¸å¿ƒåŠŸèƒ½å‡½å¼ (è™•ç†è³‡æ–™) ---
@st.cache_data
def process_dataframe(df, articles_df=None):
    df.replace('-', 'æ²’æœ‰', inplace=True)

    if articles_df is not None and not articles_df.empty:
        if 'å­¸æ ¡åç¨±' in articles_df.columns and 'æ–‡ç« æ¨™é¡Œ' in articles_df.columns and 'æ–‡ç« é€£çµ' in articles_df.columns:
            # --- ä¿®æ­£é–‹å§‹ï¼šå…ˆéæ¿¾æ‰æ¨™é¡Œæˆ–é€£çµç‚ºç©ºçš„ç„¡æ•ˆæ–‡ç« è³‡æ–™ ---
            articles_df.dropna(subset=['æ–‡ç« æ¨™é¡Œ', 'æ–‡ç« é€£çµ'], inplace=True)
            # --- ä¿®æ­£çµæŸ ---

            articles_grouped = articles_df.groupby('å­¸æ ¡åç¨±').apply(
                lambda x: list(zip(x['æ–‡ç« æ¨™é¡Œ'], x['æ–‡ç« é€£çµ']))
            ).reset_index(name='articles')
            df = pd.merge(df, articles_grouped, on='å­¸æ ¡åç¨±', how='left')
            df['articles'] = df['articles'].apply(lambda x: x if isinstance(x, list) else [])
        else:
            st.warning("Excel æª”æ¡ˆä¸­çš„ã€Œç›¸é—œæ–‡ç« ã€å·¥ä½œè¡¨ç¼ºå°‘å¿…è¦çš„æ¬„ä½ï¼ˆå­¸æ ¡åç¨±, æ–‡ç« æ¨™é¡Œ, æ–‡ç« é€£çµï¼‰ï¼Œå°‡å¿½ç•¥ç›¸é—œæ–‡ç« ã€‚")
            df['articles'] = [[] for _ in range(len(df))]
    else:
        df['articles'] = [[] for _ in range(len(df))]

    # (å…¶é¤˜è³‡æ–™è™•ç†é‚è¼¯ä¸è®Š)
    text_columns_for_features = [
        'å­¸æ ¡é—œæ³¨äº‹é …', 'å­¸ç¿’å’Œæ•™å­¸ç­–ç•¥', 'å°å­¸æ•™è‚²èª²ç¨‹æ›´æ–°é‡é»çš„ç™¼å±•', 'å…±é€šèƒ½åŠ›çš„åŸ¹é¤Š', 'æ­£ç¢ºåƒ¹å€¼è§€ã€æ…‹åº¦å’Œè¡Œç‚ºçš„åŸ¹é¤Š',
        'å…¨æ ¡åƒèˆ‡ç…§é¡§å­¸ç”Ÿçš„å¤šæ¨£æ€§', 'å…¨æ ¡åƒèˆ‡æ¨¡å¼èåˆæ•™è‚²', 'éè¯èªå­¸ç”Ÿçš„æ•™è‚²æ”¯æ´', 'èª²ç¨‹å‰ªè£åŠèª¿é©æªæ–½',
        'å®¶æ ¡åˆä½œ', 'æ ¡é¢¨', 'å­¸æ ¡ç™¼å±•è¨ˆåŠƒ', 'æ•™å¸«å°ˆæ¥­åŸ¹è¨“åŠç™¼å±•', 'å…¶ä»–æœªä¾†ç™¼å±•', 'è¾¦å­¸å®—æ—¨', 'å…¨æ–¹ä½å­¸ç¿’', 'ç‰¹åˆ¥å®¤', 'å…¶ä»–å­¸æ ¡è¨­æ–½'
    ]
    existing_feature_columns = [col for col in text_columns_for_features if col in df.columns]
    df['features_text'] = df[existing_feature_columns].fillna('').astype(str).agg(' '.join, axis=1)
    percentage_cols = [
        'å·²æ¥å—å¸«è³‡åŸ¹è¨“(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 'å­¸å£«(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 'ç¢©å£«ã€åšå£«æˆ–ä»¥ä¸Š (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 'ç‰¹æ®Šæ•™è‚²åŸ¹è¨“ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)',
        '0-4å¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', '5-9å¹´è³‡(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', '10å¹´æˆ–ä»¥ä¸Šå¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)'
    ]
    for col in percentage_cols:
        if col in df.columns:
            s = pd.to_numeric(df[col].astype(str).str.replace('%', '', regex=False), errors='coerce').fillna(0)
            if not s.empty and s.max() > 0 and s.max() <= 1: s = s * 100
            df[col] = s.round(1)
    
    teacher_count_cols = ['æ ¸å‡†ç·¨åˆ¶æ•™å¸«è·ä½æ•¸ç›®', 'å…¨æ ¡æ•™å¸«ç¸½äººæ•¸']
    for col in teacher_count_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')

    exam_count_cols = [
        'ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸', 'ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸',
        'äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸', 'äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸'
    ]
    for col in exam_count_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
            
    yes_no_cols = {
        'å°ä¸€ä¸Šå­¸æœŸä»¥å¤šå…ƒåŒ–çš„é€²å±•æ€§è©•ä¼°ä»£æ›¿æ¸¬é©—åŠè€ƒè©¦': 'p1_no_exam_assessment',
        'é¿å…ç·Šæ¥åœ¨é•·å‡æœŸå¾Œå®‰æ’æ¸¬è€ƒï¼Œè®“å­¸ç”Ÿåœ¨å‡æœŸæœ‰å……åˆ†çš„ä¼‘æ¯': 'avoid_holiday_exams',
        'æŒ‰æ ¡æƒ…éˆæ´»ç·¨æ’æ™‚é–“è¡¨ï¼Œç›¡é‡åœ¨ä¸‹åˆå®‰æ’å°ä¿®æ™‚æ®µï¼Œè®“å­¸ç”Ÿèƒ½åœ¨æ•™å¸«æŒ‡å°ä¸‹å®Œæˆéƒ¨åˆ†å®¶èª²': 'afternoon_tutorial',
        'å®¶æ•™æœƒ': 'has_pta'
    }
    for col, new_name in yes_no_cols.items():
        if col in df.columns:
            df[new_name] = df[col].apply(lambda x: 'æ˜¯' if str(x).strip().lower() in ['æœ‰', 'yes'] else 'å¦')
    
    bus_series = df['æ ¡è»Šæœå‹™'].fillna('æ²’æœ‰').astype(str) if 'æ ¡è»Šæœå‹™' in df.columns else pd.Series('æ²’æœ‰', index=df.index)
    has_bus_data = bus_series.str.strip().isin(['', 'æ²’æœ‰']) == False
    df['has_school_bus'] = 'å¦'
    df.loc[has_bus_data, 'has_school_bus'] = 'æ˜¯'
    df['bus_service_text'] = 'æ²’æœ‰'
    cond_both = bus_series.str.contains("æ ¡è»Š") & bus_series.str.contains("ä¿å§†è»Š")
    cond_bus_only = bus_series.str.contains("æ ¡è»Š") & ~bus_series.str.contains("ä¿å§†è»Š")
    cond_nanny_only = ~bus_series.str.contains("æ ¡è»Š") & bus_series.str.contains("ä¿å§†è»Š")
    df.loc[cond_both, 'bus_service_text'] = 'æœ‰æ ¡è»ŠåŠä¿å§†è»Š'
    df.loc[cond_bus_only, 'bus_service_text'] = 'æœ‰æ ¡è»Š'
    df.loc[cond_nanny_only, 'bus_service_text'] = 'æœ‰ä¿å§†è»Š'

    df['fees_text'] = 'æ²’æœ‰'
    df['has_fees'] = 'å¦'
    if 'å­¸è²»' in df.columns:
        mask_fee = df['å­¸è²»'].notna() & (df['å­¸è²»'].astype(str).str.strip() != '') & (df['å­¸è²»'].astype(str).str.strip() != 'æ²’æœ‰')
        df.loc[mask_fee, 'fees_text'] = "å­¸è²»: " + df['å­¸è²»'].astype(str)
        df.loc[mask_fee, 'has_fees'] = 'æ˜¯'
    if 'å ‚è²»' in df.columns:
        mask_sub = df['å ‚è²»'].notna() & (df['å ‚è²»'].astype(str).str.strip() != '') & (df['å ‚è²»'].astype(str).str.strip() != 'æ²’æœ‰')
        mask_both = (df['has_fees'] == 'æ˜¯') & mask_sub
        df.loc[mask_both, 'fees_text'] += ' | ' + "å ‚è²»: " + df['å ‚è²»'].astype(str)
        mask_sub_only = (df['has_fees'] == 'å¦') & mask_sub
        df.loc[mask_sub_only, 'fees_text'] = "å ‚è²»: " + df['å ‚è²»'].astype(str)
        df.loc[mask_sub, 'has_fees'] = 'æ˜¯'

    feeder_cols = ['ä¸€æ¢é¾ä¸­å­¸', 'ç›´å±¬ä¸­å­¸', 'è¯ç¹«ä¸­å­¸']
    existing_feeder_cols = [col for col in feeder_cols if col in df.columns]
    if existing_feeder_cols:
         df['has_feeder_school'] = df[existing_feeder_cols].apply(
            lambda row: 'æ˜¯' if any(pd.notna(val) and str(val).strip() not in ['', 'æ²’æœ‰'] for val in row) else 'å¦',
            axis=1
        )
    else:
        df['has_feeder_school'] = 'å¦'
    return df

# --- æª”æ¡ˆä¸Šå‚³å™¨ ---
uploaded_file = st.file_uploader("**è«‹ä¸Šå‚³æ‚¨çš„å­¸æ ¡è³‡æ–™æª”æ¡ˆ (Excel æˆ– CSV)**", type=['csv', 'xlsx'])

if uploaded_file is not None:
    try:
        main_dataframe = None
        articles_dataframe = None
        if uploaded_file.name.endswith('.csv'):
            main_dataframe = pd.read_csv(uploaded_file, engine='python')
            st.info("æ‚¨ä¸Šå‚³çš„æ˜¯ CSV æª”æ¡ˆï¼Œå°‡åªè®€å–å­¸æ ¡è³‡æ–™ã€‚")
        else:
            try:
                main_dataframe = pd.read_excel(uploaded_file, sheet_name='å­¸æ ¡è³‡æ–™', engine='openpyxl')
                articles_dataframe = pd.read_excel(uploaded_file, sheet_name='ç›¸é—œæ–‡ç« ', engine='openpyxl')
            except Exception as e:
                st.error(f"è®€å– Excel æª”æ¡ˆå¤±æ•—ï¼š{e}")
                st.warning("è«‹ç¢ºèªæ‚¨çš„ Excel æª”æ¡ˆåŒ…å«åç‚ºã€Œå­¸æ ¡è³‡æ–™ã€å’Œã€Œç›¸é—œæ–‡ç« ã€çš„å·¥ä½œè¡¨ã€‚")
                main_dataframe = None

        if main_dataframe is not None:
            processed_df = process_dataframe(main_dataframe, articles_dataframe)
            st.success(f'æˆåŠŸè®€å– {len(processed_df)} ç­†å­¸æ ¡è³‡æ–™ï¼')
            
            active_filters = []
            with st.expander("ğŸ“ æŒ‰å­¸æ ¡åç¨±æœå°‹", expanded=True):
                search_keyword = st.text_input("**è¼¸å…¥å­¸æ ¡åç¨±é—œéµå­—ï¼š**")
                if search_keyword: active_filters.append(('name', search_keyword))
            with st.expander("â„¹ï¸ æŒ‰å­¸æ ¡åŸºæœ¬è³‡æ–™æœå°‹", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    if 'å­¸æ ¡é¡åˆ¥' in processed_df.columns:
                        cat_options = sorted(processed_df['å­¸æ ¡é¡åˆ¥'].dropna().unique()); selected_cats = st.multiselect("å­¸æ ¡é¡åˆ¥", options=cat_options)
                        if selected_cats: active_filters.append(('category', selected_cats))
                    if 'å­¸ç”Ÿæ€§åˆ¥' in processed_df.columns:
                        gender_options = sorted(processed_df['å­¸ç”Ÿæ€§åˆ¥'].dropna().unique()); selected_genders = st.multiselect("å­¸ç”Ÿæ€§åˆ¥", options=gender_options)
                        if selected_genders: active_filters.append(('gender', selected_genders))
                    if 'å®—æ•™' in processed_df.columns:
                        religion_options = sorted(processed_df['å®—æ•™'].dropna().unique()); selected_religions = st.multiselect("å®—æ•™", options=religion_options)
                        if selected_religions: active_filters.append(('religion', selected_religions))
                    if 'æ•™å­¸èªè¨€' in processed_df.columns:
                        lang_options = ['ä¸é™'] + sorted(processed_df['æ•™å­¸èªè¨€'].dropna().unique())
                        selected_lang = st.selectbox("æ•™è‚²èªè¨€", options=lang_options)
                        if selected_lang != 'ä¸é™': active_filters.append(('language', selected_lang))
                with col2:
                    if 'è¾¦å­¸åœ˜é«”' in processed_df.columns:
                        body_counts = processed_df['è¾¦å­¸åœ˜é«”'].value_counts()
                        body_options = sorted(body_counts[body_counts >= 2].index)
                        selected_bodies = st.multiselect("è¾¦å­¸åœ˜é«” (åªé¡¯ç¤ºå¤šæ–¼ä¸€é–“çš„åœ˜é«”)", options=body_options)
                        if selected_bodies: active_filters.append(('body', selected_bodies))
                    fee_choice = st.radio("å­¸è²»æˆ–å ‚è²»", ['ä¸é™', 'æœ‰', 'æ²’æœ‰'], horizontal=True, key='fees')
                    if fee_choice == 'æœ‰': active_filters.append(('fees', 'æ˜¯'))
                    elif fee_choice == 'æ²’æœ‰': active_filters.append(('fees', 'å¦'))
                    feeder_choice = st.radio("æœ‰é—œè¯ä¸­å­¸ï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True, key='feeder')
                    if feeder_choice != 'ä¸é™': active_filters.append(('feeder', feeder_choice))
                    bus_choice = st.radio("æœ‰æ ¡è»Šæˆ–ä¿å§†è»Šæœå‹™ï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True, key='bus')
                    if bus_choice != 'ä¸é™': active_filters.append(('bus', bus_choice))
            with st.expander("ğŸ“ æŒ‰åœ°å€åŠæ ¡ç¶²æœå°‹", expanded=False):
                col1, col2 = st.columns(2)
                with col1:
                    all_districts = sorted(processed_df['åœ°å€'].dropna().unique()); selected_districts = st.multiselect("**é¸æ“‡åœ°å€ (å¯å¤šé¸)**", options=all_districts)
                    if selected_districts: active_filters.append(('district', selected_districts))
                with col2:
                    if selected_districts: available_nets = sorted(processed_df[processed_df['åœ°å€'].isin(selected_districts)]['æ ¡ç¶²'].dropna().unique())
                    else: available_nets = sorted(processed_df['æ ¡ç¶²'].dropna().unique())
                    selected_nets = st.multiselect("**é¸æ“‡æ ¡ç¶² (å¯å¤šé¸)**", options=available_nets)
                    if selected_nets: active_filters.append(('net', selected_nets))
            with st.expander("ğŸŒŸ æŒ‰è¾¦å­¸ç‰¹è‰²æœå°‹", expanded=False):
                feature_mapping = {"ã€æ•™å­¸æ¨¡å¼èˆ‡é‡é»ã€‘": {"è‡ªä¸»å­¸ç¿’åŠæ¢ç©¶": ['è‡ªä¸»å­¸ç¿’', 'æ¢ç©¶'],"STEAM": ['STEAM', 'å‰µå®¢'], "é›»å­å­¸ç¿’": ['é›»å­å­¸ç¿’', 'e-learning'], "é–±è®€": ['é–±è®€'], "è³‡å„ªæ•™è‚²": ['è³‡å„ª'], "å°ˆé¡Œç ”ç¿’": ['å°ˆé¡Œç ”ç¿’'], "è·¨èª²ç¨‹å­¸ç¿’": ['è·¨èª²ç¨‹'], "å…©æ–‡ä¸‰èª": ['å…©æ–‡ä¸‰èª'], "è‹±æ–‡æ•™è‚²": ['è‹±æ–‡'], "å®¶æ ¡åˆä½œ": ['å®¶æ ¡åˆä½œ'], "å¢ƒå¤–äº¤æµ": ['å¢ƒå¤–äº¤æµ'], "è—è¡“": ['è—è¡“'], "é«”è‚²": ['é«”è‚²']},"ã€åƒ¹å€¼è§€èˆ‡å“å¾·ã€‘": {"ä¸­è¯æ–‡åŒ–æ•™è‚²": ['ä¸­è¯æ–‡åŒ–'], "æ­£å‘ã€åƒ¹å€¼è§€ã€ç”Ÿå‘½æ•™è‚²": ['æ­£å‘', 'åƒ¹å€¼è§€', 'ç”Ÿå‘½æ•™è‚²'], "åœ‹æ°‘æ•™è‚²ã€åœ‹å®‰æ•™è‚²": ['åœ‹æ°‘', 'åœ‹å®‰'], "æœå‹™æ•™è‚²": ['æœå‹™'], "é—œæ„›åŠç²¾ç¥å¥åº·": ['é—œæ„›', 'å¥åº·']},"ã€å­¸ç”Ÿæ”¯æ´èˆ‡ç™¼å±•ã€‘": {"å…¨äººç™¼å±•": ['å…¨äººç™¼å±•', 'å¤šå…ƒç™¼å±•'], "ç”Ÿæ¶¯è¦åŠƒã€å•Ÿç™¼æ½›èƒ½": ['ç”Ÿæ¶¯è¦åŠƒ', 'æ½›èƒ½'], "æ‹”å°–è£œåº•ã€ç…§é¡§å·®ç•°": ['æ‹”å°–è£œåº•', 'å€‹åˆ¥å·®ç•°'], "èåˆæ•™è‚²": ['èåˆæ•™è‚²']}}
                col1, col2, col3 = st.columns(3); all_selected_options = []
                with col1: selected1 = st.multiselect("æ•™å­¸æ¨¡å¼èˆ‡é‡é»", options=list(feature_mapping["ã€æ•™å­¸æ¨¡å¼èˆ‡é‡é»ã€‘"].keys())); all_selected_options.extend(selected1)
                with col2: selected2 = st.multiselect("åƒ¹å€¼è§€èˆ‡å“å¾·", options=list(feature_mapping["ã€åƒ¹å€¼è§€èˆ‡å“å¾·ã€‘"].keys())); all_selected_options.extend(selected2)
                with col3: selected3 = st.multiselect("å­¸ç”Ÿæ”¯æ´èˆ‡ç™¼å±•", options=list(feature_mapping["ã€å­¸ç”Ÿæ”¯æ´èˆ‡ç™¼å±•ã€‘"].keys())); all_selected_options.extend(selected3)
                if all_selected_options: active_filters.append(('features', all_selected_options))
            with st.expander("ğŸ“ æŒ‰å¸«è³‡æ¢ä»¶æœå°‹", expanded=False):
                slider_options = {'å·²æ¥å—å¸«è³‡åŸ¹è¨“(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'å¸«è³‡åŸ¹è¨“æ¯”ä¾‹ (%)', 'å­¸å£«(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'å­¸å£«å­¸æ­·æ¯”ä¾‹ (%)', 'ç¢©å£«ã€åšå£«æˆ–ä»¥ä¸Š (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'ç¢©å£«æˆ–ä»¥ä¸Šå­¸æ­·æ¯”ä¾‹ (%)', 'ç‰¹æ®Šæ•™è‚²åŸ¹è¨“ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'ç‰¹æ®Šæ•™è‚²åŸ¹è¨“æ¯”ä¾‹ (%)', '0-4å¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': '0-4å¹´è³‡æ¯”ä¾‹ (%)', '5-9å¹´è³‡(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': '5-9å¹´è³‡æ¯”ä¾‹ (%)', '10å¹´æˆ–ä»¥ä¸Šå¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': '10å¹´ä»¥ä¸Šå¹´è³‡æ¯”ä¾‹ (%)'}
                for col_name, slider_label in slider_options.items():
                    if col_name in processed_df.columns:
                        min_val = st.slider(slider_label, 0, 100, 0, 5, key=col_name)
                        if min_val > 0: active_filters.append(('slider', (col_name, min_val)))
            with st.expander("ğŸ“š æŒ‰èª²æ¥­å®‰æ’æœå°‹", expanded=False):
                st.markdown("**è©•ä¼°æ¬¡æ•¸**"); col1, col2 = st.columns(2)
                with col1:
                    max_p1_tests = st.selectbox('å°ä¸€å…¨å¹´æœ€å¤šæ¸¬é©—æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3, 4], index=0, key='p1_test')
                    if max_p1_tests != 'ä»»ä½•æ¬¡æ•¸': active_filters.append(('max_p1_tests', max_p1_tests))
                    max_p2_6_tests = st.selectbox('äºŒè‡³å…­å¹´ç´šæœ€å¤šæ¸¬é©—æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3, 4], index=0, key='p2-6_test')
                    if max_p2_6_tests != 'ä»»ä½•æ¬¡æ•¸': active_filters.append(('max_p2_6_tests', max_p2_6_tests))
                with col2:
                    max_p1_exams = st.selectbox('å°ä¸€å…¨å¹´æœ€å¤šè€ƒè©¦æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3], index=0, key='p1_exam')
                    if max_p1_exams != 'ä»»ä½•æ¬¡æ•¸': active_filters.append(('max_p1_exams', max_p1_exams))
                    max_p2_6_exams = st.selectbox('äºŒè‡³å…­å¹´ç´šæœ€å¤šè€ƒè©¦æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3, 4], index=0, key='p2-6_exam')
                    if max_p2_6_exams != 'ä»»ä½•æ¬¡æ•¸': active_filters.append(('max_p2_6_exams', max_p2_6_exams))
                st.markdown("**å…¶ä»–å®‰æ’**"); p1_no_exam = st.radio("å°ä¸€ä¸Šå­¸æœŸä»¥å¤šå…ƒåŒ–è©•ä¼°ä»£æ›¿æ¸¬è€ƒï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True)
                if p1_no_exam != 'ä¸é™': active_filters.append(('p1_no_exam', p1_no_exam))
                avoid_holiday = st.radio("é¿å…é•·å‡å¾Œæ¸¬è€ƒï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True, key='holiday')
                if avoid_holiday != 'ä¸é™': active_filters.append(('avoid_holiday', avoid_holiday))
                afternoon_tut = st.radio("è¨­ä¸‹åˆå°ä¿®æ™‚æ®µï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True, key='tutorial')
                if afternoon_tut != 'ä¸é™': active_filters.append(('afternoon_tut', afternoon_tut))
            
            if active_filters != st.session_state.get('active_filters_cache', None):
                st.session_state.page = 0
                st.session_state.active_filters_cache = active_filters

            st.markdown("---"); st.header(f"æœå°‹çµæœ")
            if not active_filters:
                st.info("â˜ï¸ è«‹ä½¿ç”¨ä¸Šæ–¹çš„ç¯©é¸å™¨é–‹å§‹å°‹æ‰¾å­¸æ ¡ã€‚")
            else:
                filtered_df = processed_df.copy()
                all_selected_keywords_for_highlight = []
                for filter_type, value in active_filters:
                    if filter_type == 'name': filtered_df = filtered_df[filtered_df['å­¸æ ¡åç¨±'].str.contains(value, case=False, na=False)]
                    elif filter_type == 'category': filtered_df = filtered_df[filtered_df['å­¸æ ¡é¡åˆ¥'].isin(value)]
                    elif filter_type == 'gender': filtered_df = filtered_df[filtered_df['å­¸ç”Ÿæ€§åˆ¥'].isin(value)]
                    elif filter_type == 'religion': filtered_df = filtered_df[filtered_df['å®—æ•™'].isin(value)]
                    elif filter_type == 'language': filtered_df = filtered_df[filtered_df['æ•™å­¸èªè¨€'] == value]
                    elif filter_type == 'body': filtered_df = filtered_df[filtered_df['è¾¦å­¸åœ˜é«”'].isin(value)]
                    elif filter_type == 'fees': filtered_df = filtered_df[filtered_df['has_fees'] == value]
                    elif filter_type == 'feeder': filtered_df = filtered_df[filtered_df['has_feeder_school'] == value]
                    elif filter_type == 'bus': filtered_df = filtered_df[filtered_df['has_school_bus'] == value]
                    elif filter_type == 'district': filtered_df = filtered_df[filtered_df['åœ°å€'].isin(value)]
                    elif filter_type == 'net': filtered_df = filtered_df[filtered_df['æ ¡ç¶²'].isin(value)]
                    elif filter_type == 'features':
                        for option in value:
                            search_terms = [];
                            for category in feature_mapping.values():
                                if option in category: search_terms = category[option]; all_selected_keywords_for_highlight.extend(search_terms); break
                            if search_terms:
                                regex_pattern = '|'.join([re.escape(term) for term in search_terms])
                                filtered_df = filtered_df[filtered_df['features_text'].str.contains(regex_pattern, case=False, na=False, regex=True)]
                    elif filter_type == 'slider':
                        col_name, min_val = value; filtered_df = filtered_df[filtered_df[col_name] >= min_val]
                    elif filter_type == 'max_p1_tests': filtered_df = filtered_df[filtered_df['ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸'] <= int(value)]
                    elif filter_type == 'max_p2_6_tests': filtered_df = filtered_df[filtered_df['äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸'] <= int(value)]
                    elif filter_type == 'max_p1_exams': filtered_df = filtered_df[filtered_df['ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸'] <= int(value)]
                    elif filter_type == 'max_p2_6_exams': filtered_df = filtered_df[filtered_df['äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸'] <= int(value)]
                    elif filter_type == 'p1_no_exam': filtered_df = filtered_df[filtered_df['p1_no_exam_assessment'] == value]
                    elif filter_type == 'avoid_holiday': filtered_df = filtered_df[filtered_df['avoid_holiday_exams'] == value]
                    elif filter_type == 'afternoon_tut': filtered_df = filtered_df[filtered_df['afternoon_tutorial'] == value]
                
                st.info(f"ç¶œåˆæ‰€æœ‰æ¢ä»¶ï¼Œå…±æ‰¾åˆ° {len(filtered_df)} æ‰€å­¸æ ¡ã€‚")
                
                if not filtered_df.empty:
                    ITEMS_PER_PAGE = 10
                    total_items = len(filtered_df)
                    total_pages = (total_items + ITEMS_PER_PAGE - 1) // ITEMS_PER_PAGE
                    st.session_state.page = max(0, min(st.session_state.page, total_pages - 1))
                    
                    start_idx = st.session_state.page * ITEMS_PER_PAGE
                    end_idx = min(start_idx + ITEMS_PER_PAGE, total_items)
                    
                    page_df = filtered_df.iloc[start_idx:end_idx]
                    
                    for index, school in page_df.iterrows():
                        with st.expander(f"**{school.get('å­¸æ ¡åç¨±', 'N/A')}** ({school.get('åœ°å€', 'N/A')})"):
                            articles = school.get('articles', [])
                            if articles:
                                st.markdown("#### ğŸ“– ç›¸é—œå ±å°")
                                for title, url in articles:
                                    image_url = get_article_metadata(url)
                                    if image_url:
                                        st.markdown(
                                            f'<a href="{url}" target="_blank"><img src="{image_url}" alt="{title}" style="width:100%; max-width:400px; border-radius: 8px; margin-bottom: 5px;"></a>', 
                                            unsafe_allow_html=True
                                        )
                                        st.markdown(f'**<a href="{url}" target="_blank" style="text-decoration: none; color: #333;">{title}</a>**', unsafe_allow_html=True)
                                    else:
                                        st.markdown(f"- [{title}]({url})")
                                st.markdown("---")

                            st.markdown("#### ğŸ“– å­¸æ ¡åŸºæœ¬è³‡æ–™")
                            info_col1, info_col2 = st.columns(2)
                            with info_col1:
                                st.write(f"**å­¸æ ¡é¡åˆ¥:** {school.get('å­¸æ ¡é¡åˆ¥', 'æœªæä¾›')}"); st.write(f"**è¾¦å­¸åœ˜é«”:** {school.get('è¾¦å­¸åœ˜é«”', 'æœªæä¾›')}"); st.write(f"**å‰µæ ¡å¹´ä»½:** {school.get('å‰µæ ¡å¹´ä»½', 'æœªæä¾›')}"); st.write(f"**æ ¡é•·:** {school.get('æ ¡é•·_', 'æœªæä¾›')}"); st.write(f"**æ•™å­¸èªè¨€:** {school.get('æ•™å­¸èªè¨€', 'æœªæä¾›')}")
                            with info_col2:
                                st.write(f"**å­¸ç”Ÿæ€§åˆ¥:** {school.get('å­¸ç”Ÿæ€§åˆ¥', 'æœªæä¾›')}"); st.write(f"**å®—æ•™:** {school.get('å®—æ•™', 'æœªæä¾›')}"); st.write(f"**å­¸æ ¡ä½”åœ°é¢ç©:** {school.get('å­¸æ ¡ä½”åœ°é¢ç©', 'æœªæä¾›')}"); st.write(f"**æ ¡ç›£:** {school.get('æ ¡ç›£ï¼å­¸æ ¡ç®¡ç†å§”å“¡æœƒä¸»å¸­', 'æœªæä¾›')}"); st.write(f"**å®¶æ•™æœƒ:** {school.get('has_pta', 'æœªæä¾›')}")
                            
                            st.write(f"**å­¸è²»/å ‚è²»:** {school.get('fees_text', 'æ²’æœ‰')}")
                            st.write(f"**æ ¡è»Šæœå‹™:** {school.get('bus_service_text', 'æ²’æœ‰')}")
                            
                            feeder_schools = {"ä¸€æ¢é¾ä¸­å­¸": school.get('ä¸€æ¢é¾ä¸­å­¸'), "ç›´å±¬ä¸­å­¸": school.get('ç›´å±¬ä¸­å­¸'), "è¯ç¹«ä¸­å­¸": school.get('è¯ç¹«ä¸­å­¸')}
                            for title, value in feeder_schools.items():
                                if pd.notna(value) and str(value).strip() not in ['', 'æ²’æœ‰']: st.write(f"**{title}:** {value}")
                            
                            st.markdown("---")
                            st.markdown("#### ğŸ« å­¸æ ¡è¨­æ–½è©³æƒ…")
                            facility_counts = (f"ğŸ« èª²å®¤: {school.get('èª²å®¤æ•¸ç›®', 'N/A')} | ğŸ›ï¸ ç¦®å ‚: {school.get('ç¦®å ‚æ•¸ç›®', 'N/A')} | ğŸ¤¸ æ“å ´: {school.get('æ“å ´æ•¸ç›®', 'N/A')} | ğŸ“š åœ–æ›¸é¤¨: {school.get('åœ–æ›¸é¤¨æ•¸ç›®', 'N/A')}")
                            st.markdown(facility_counts)
                            other_facilities = {"ç‰¹åˆ¥å®¤": "ç‰¹åˆ¥å®¤", "æ”¯æ´æœ‰ç‰¹æ®Šæ•™è‚²éœ€è¦å­¸ç”Ÿçš„è¨­æ–½": "SEN æ”¯æ´è¨­æ–½", "å…¶ä»–å­¸æ ¡è¨­æ–½": "å…¶ä»–å­¸æ ¡è¨­æ–½"}
                            for column_name, display_title in other_facilities.items():
                                detail_value = school.get(column_name, '');
                                if pd.notna(detail_value) and str(detail_value).strip() not in ['', 'æ²’æœ‰']: st.write(f"**{display_title}:** {detail_value}")
                            
                            st.markdown("---")
                            st.markdown("#### ğŸ§‘â€ğŸ« å¸«è³‡åœ˜éšŠæ¦‚è¦½")
                            approved_teachers = school.get('æ ¸å‡†ç·¨åˆ¶æ•™å¸«è·ä½æ•¸ç›®')
                            total_teachers = school.get('å…¨æ ¡æ•™å¸«ç¸½äººæ•¸')
                            col1, col2 = st.columns(2)
                            with col1:
                                if pd.isna(approved_teachers):
                                    st.metric("æ ¸å‡†ç·¨åˆ¶æ•™å¸«è·ä½", "æ²’æœ‰è³‡æ–™")
                                else:
                                    st.metric("æ ¸å‡†ç·¨åˆ¶æ•™å¸«è·ä½", f"{int(approved_teachers)} äºº")
                            with col2:
                                if pd.isna(total_teachers):
                                    st.metric("å…¨æ ¡æ•™å¸«ç¸½äººæ•¸", "æ²’æœ‰è³‡æ–™")
                                else:
                                    if not pd.isna(approved_teachers):
                                        diff = total_teachers - approved_teachers
                                        if diff >= 0:
                                            st.metric("å…¨æ ¡æ•™å¸«ç¸½äººæ•¸", f"{int(total_teachers)} äºº", f"+{int(diff)}", delta_color="normal")
                                        else:
                                            st.metric("å…¨æ ¡æ•™å¸«ç¸½äººæ•¸", f"{int(total_teachers)} äºº", f"{int(diff)}", delta_color="inverse")
                                    else:
                                        st.metric("å…¨æ ¡æ•™å¸«ç¸½äººæ•¸", f"{int(total_teachers)} äºº")
                            if st.button("ğŸ“Š é¡¯ç¤ºå¸«è³‡æ¯”ä¾‹åœ–è¡¨", key=f"chart_btn_{index}"):
                                st.markdown("#### ğŸ“Š å¸«è³‡æ¯”ä¾‹åˆ†ä½ˆåœ–"); pie_col1, pie_col2 = st.columns(2)
                                with pie_col1:
                                    st.markdown("**å­¸æ­·åˆ†ä½ˆ**"); edu_data = {'é¡åˆ¥': ['å­¸å£«', 'ç¢©å£«æˆ–ä»¥ä¸Š'],'æ¯”ä¾‹': [school.get('å­¸å£«(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0), school.get('ç¢©å£«ã€åšå£«æˆ–ä»¥ä¸Š (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0)]}; edu_df = pd.DataFrame(edu_data)
                                    if edu_df['æ¯”ä¾‹'].sum() > 0:
                                        fig1 = px.pie(edu_df, values='æ¯”ä¾‹', names='é¡åˆ¥', color_discrete_sequence=px.colors.sequential.Greens_r);
                                        fig1.update_layout(showlegend=False, margin=dict(l=10, r=10, t=30, b=10), height=300, font=dict(size=14))
                                        fig1.update_traces(textposition='outside', textinfo='percent+label'); st.plotly_chart(fig1, use_container_width=True, key=f"edu_pie_{index}")
                                    else: st.text("ç„¡ç›¸é—œæ•¸æ“š")
                                with pie_col2:
                                    st.markdown("**å¹´è³‡åˆ†ä½ˆ**"); exp_data = {'é¡åˆ¥': ['0-4å¹´', '5-9å¹´', '10å¹´ä»¥ä¸Š'],'æ¯”ä¾‹': [school.get('0-4å¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0), school.get('5-9å¹´è³‡(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0), school.get('10å¹´æˆ–ä»¥ä¸Šå¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0)]}; exp_df = pd.DataFrame(exp_data)
                                    if exp_df['æ¯”ä¾‹'].sum() > 0:
                                        fig2 = px.pie(exp_df, values='æ¯”ä¾‹', names='é¡åˆ¥', color_discrete_sequence=px.colors.sequential.Blues_r);
                                        fig2.update_layout(showlegend=False, margin=dict(l=10, r=10, t=30, b=10), height=300, font=dict(size=14))
                                        fig2.update_traces(textposition='outside', textinfo='percent+label'); st.plotly_chart(fig2, use_container_width=True, key=f"exp_pie_{index}")
                                    else: st.text("ç„¡ç›¸é—œæ•¸æ“š")
                            st.markdown("---")
                            st.markdown("#### ğŸ“š èª²æ¥­èˆ‡è©•ä¼°å®‰æ’")
                            homework_details = {"å°ä¸€æ¸¬é©—/è€ƒè©¦æ¬¡æ•¸": f"{school.get('ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸', 'N/A')} / {school.get('ä¸€å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸', 'N/A')}", "é«˜å¹´ç´šæ¸¬é©—/è€ƒè©¦æ¬¡æ•¸": f"{school.get('äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘æ¸¬é©—æ¬¡æ•¸', 'N/A')} / {school.get('äºŒè‡³å…­å¹´ç´šå…¨å¹´å…¨ç§‘è€ƒè©¦æ¬¡æ•¸', 'N/A')}", "å°ä¸€å…è©¦è©•ä¼°": school.get('p1_no_exam_assessment', 'N/A'), "å¤šå…ƒå­¸ç¿’è©•ä¼°": school.get('å¤šå…ƒå­¸ç¿’è©•ä¼°', 'æœªæä¾›'), "é¿å…é•·å‡å¾Œæ¸¬è€ƒ": school.get('avoid_holiday_exams', 'N/A'), "ä¸‹åˆå°ä¿®æ™‚æ®µ": school.get('afternoon_tutorial', 'N/A')}
                            for title, value in homework_details.items():
                                if pd.notna(value) and str(value).strip() != '': st.write(f"**{title}:** {value}")
                            
                            st.markdown("---")
                            st.markdown("#### âœ¨ è¾¦å­¸ç‰¹è‰²èˆ‡ç™¼å±•è¨ˆåŠƒ")
                            feature_text_map = {
                                "å­¸æ ¡é—œæ³¨äº‹é …": "å­¸æ ¡é—œæ³¨äº‹é …", "å­¸ç¿’å’Œæ•™å­¸ç­–ç•¥": "å­¸ç¿’å’Œæ•™å­¸ç­–ç•¥", "å°å­¸æ•™è‚²èª²ç¨‹æ›´æ–°é‡é»çš„ç™¼å±•": "èª²ç¨‹æ›´æ–°é‡é»", 
                                "å…±é€šèƒ½åŠ›çš„åŸ¹é¤Š": "å…±é€šèƒ½åŠ›åŸ¹é¤Š", "æ­£ç¢ºåƒ¹å€¼è§€ã€æ…‹åº¦å’Œè¡Œç‚ºçš„åŸ¹é¤Š": "åƒ¹å€¼è§€åŸ¹é¤Š", "å…¨æ ¡åƒèˆ‡ç…§é¡§å­¸ç”Ÿçš„å¤šæ¨£æ€§": "ç…§é¡§å­¸ç”Ÿå¤šæ¨£æ€§",
                                "å…¨æ ¡åƒèˆ‡æ¨¡å¼èåˆæ•™è‚²": "èåˆæ•™è‚²æ¨¡å¼", "éè¯èªå­¸ç”Ÿçš„æ•™è‚²æ”¯æ´": "éè¯èªå­¸ç”Ÿæ”¯æ´", "èª²ç¨‹å‰ªè£åŠèª¿é©æªæ–½": "èª²ç¨‹å‰ªè£èª¿é©",
                                "å®¶æ ¡åˆä½œ": "å®¶æ ¡åˆä½œ", "æ ¡é¢¨": "æ ¡é¢¨", "å­¸æ ¡ç™¼å±•è¨ˆåŠƒ": "å­¸æ ¡ç™¼å±•è¨ˆåŠƒ", "æ•™å¸«å°ˆæ¥­åŸ¹è¨“åŠç™¼å±•": "æ•™å¸«å°ˆæ¥­ç™¼å±•", 
                                "å…¶ä»–æœªä¾†ç™¼å±•": "å…¶ä»–æœªä¾†ç™¼å±•"
                            }
                            for column_name, display_title in feature_text_map.items():
                                detail_value = school.get(column_name, '')
                                if pd.notna(detail_value) and str(detail_value).strip() not in ['', 'æ²’æœ‰']:
                                    
                                    should_expand = False
                                    if all_selected_keywords_for_highlight:
                                        text_to_check = str(detail_value).lower()
                                        if any(keyword.lower() in text_to_check for keyword in all_selected_keywords_for_highlight):
                                            should_expand = True
                                    
                                    with st.expander(f"**{display_title}**", expanded=should_expand):
                                        formatted_content = format_and_highlight_text(detail_value, all_selected_keywords_for_highlight)
                                        st.markdown(formatted_content, unsafe_allow_html=True)

                    st.markdown("---")
                    col1, col2, col3 = st.columns([2, 3, 2])
                    if total_pages > 1:
                        with col1:
                            if st.session_state.page > 0:
                                if st.button("â¬…ï¸ ä¸Šä¸€é "):
                                    st.session_state.page -= 1
                                    st.rerun()
                        with col2:
                            st.write(f"é æ•¸: {st.session_state.page + 1} / {total_pages}")
                        with col3:
                            if st.session_state.page < total_pages - 1:
                                if st.button("ä¸‹ä¸€é  â¡ï¸"):
                                    st.session_state.page += 1
                                    st.rerun()

    except Exception as e:
        st.error(f"æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{e}")

else:
    st.info("è«‹å…ˆä¸Šå‚³æ‚¨çš„è³‡æ–™æª”æ¡ˆã€‚å»ºè­°ä½¿ç”¨åŒ…å«ã€Œå­¸æ ¡è³‡æ–™ã€å’Œã€Œç›¸é—œæ–‡ç« ã€å…©å€‹å·¥ä½œè¡¨çš„ Excel æª”æ¡ˆã€‚")
