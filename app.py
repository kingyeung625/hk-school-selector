import streamlit as st
import pandas as pd
import plotly.express as px
import re
import os
import requests
from bs4 import BeautifulSoup

# --- Streamlit æ‡‰ç”¨ç¨‹å¼ä»‹é¢ ---
st.set_page_config(page_title="ã€Œ01æ•™è‚²ã€å°å­¸æ¦‚è¦½æœå°‹å™¨", layout="centered")
st.title('ã€Œ01æ•™è‚²ã€å°å­¸æ¦‚è¦½æœå°‹å™¨')
st.markdown(
    '<div style="border: 2px dashed #cccccc; padding: 20px; text-align: center; margin-top: 20px; margin-bottom: 20px;">å»£å‘Šç©ºé–“</div>',
    unsafe_allow_html=True
)
st.write("ä½¿ç”¨ä¸‹æ–¹çš„ç¯©é¸å™¨ä¾†å°‹æ‰¾å¿ƒå„€çš„å­¸æ ¡ã€‚")

# --- åˆå§‹åŒ– Session State ---
if 'page' not in st.session_state:
    st.session_state.page = 0
if 'active_filters_cache' not in st.session_state:
    st.session_state.active_filters_cache = None

# --- ç²å–æ–‡ç«  Meta Data çš„å¿«å–å‡½å¼ ---
@st.cache_data(ttl=3600)
def get_article_metadata(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        og_image_tag = soup.find('meta', property='og:image')
        
        if og_image_tag and og_image_tag.get('content'):
            return og_image_tag['content']
            
    except requests.RequestException:
        return None
    return None

# --- æ–‡å­—è™•ç†å‡½å¼ ---
def format_and_highlight_text(text, keywords):
    text_str = str(text).strip()
    if not text_str: return ""
    list_marker_pattern = re.compile(r'(\s*[ï¼ˆ(]?\d+[.)ï¼‰]\s*|\s*[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*)')
    parts = list_marker_pattern.split(text_str)
    html_output = f'<p style="margin:0; padding:0;">{parts[0]}'
    for i in range(1, len(parts), 2):
        if i + 1 < len(parts):
            marker = parts[i].strip(); content = parts[i+1].strip()
            html_output += f'<div style="margin-left: 2em; text-indent: -2em; padding-top: 5px;">{marker} {content}</div>'
    html_output += '</p>'
    if keywords:
        flat_keywords = []
        for item in keywords:
            if isinstance(item, list):
                flat_keywords.extend(item)
            else:
                flat_keywords.append(item)
        
        pattern = '|'.join([re.escape(keyword) for keyword in flat_keywords])
        if pattern:
            html_output = re.sub(
                pattern,
                lambda match: f'<span style="background-color: yellow;">{match.group(0)}</span>',
                html_output,
                flags=re.IGNORECASE
            )
    return html_output

# --- æ ¸å¿ƒåŠŸèƒ½å‡½å¼ (è™•ç†è³‡æ–™) ---
@st.cache_data
def process_dataframe(df, articles_df=None, net_df=None):
    df.replace('-', 'æ²’æœ‰', inplace=True)

    if net_df is not None and not net_df.empty:
        if 'å­¸æ ¡åç¨±' in net_df.columns and 'åœ°å€' in net_df.columns and 'æ ¡ç¶²' in net_df.columns:
            df = pd.merge(df, net_df[['å­¸æ ¡åç¨±', 'åœ°å€', 'æ ¡ç¶²']], on='å­¸æ ¡åç¨±', how='left')
        else:
            st.warning("Excel æª”æ¡ˆä¸­çš„ã€Œæ ¡ç¶²è³‡æ–™ã€å·¥ä½œè¡¨ç¼ºå°‘å¿…è¦çš„æ¬„ä½ï¼ˆå­¸æ ¡åç¨±, åœ°å€, æ ¡ç¶²ï¼‰ã€‚")

    if articles_df is not None and not articles_df.empty:
        if 'å­¸æ ¡åç¨±' in articles_df.columns and 'æ–‡ç« æ¨™é¡Œ' in articles_df.columns and 'æ–‡ç« é€£çµ' in articles_df.columns:
            articles_df.dropna(subset=['æ–‡ç« æ¨™é¡Œ', 'æ–‡ç« é€£çµ'], inplace=True)
            articles_grouped = articles_df.groupby('å­¸æ ¡åç¨±').apply(
                lambda x: list(zip(x['æ–‡ç« æ¨™é¡Œ'], x['æ–‡ç« é€£çµ']))
            ).reset_index(name='articles')
            df = pd.merge(df, articles_grouped, on='å­¸æ ¡åç¨±', how='left')
            df['articles'] = df['articles'].apply(lambda x: x if isinstance(x, list) else [])
        else:
            st.warning("Excel æª”æ¡ˆä¸­çš„ã€Œç›¸é—œæ–‡ç« ã€å·¥ä½œè¡¨ç¼ºå°‘å¿…è¦çš„æ¬„ä½ï¼ˆå­¸æ ¡åç¨±, æ–‡ç« æ¨™é¡Œ, æ–‡ç« é€£çµï¼‰ï¼Œå°‡å¿½ç•¥ç›¸é—œæ–‡ç« ã€‚")
            df['articles'] = [[] for _ in range(len(df))]
    else:
        df['articles'] = [[] for _ in range(len(df))]
    
    df['full_text_search'] = df.astype(str).agg(' '.join, axis=1)

    text_columns_for_features = ['å­¸æ ¡ç™¼å±•è¨ˆåŠƒ', 'å­¸ç¿’å’Œæ•™å­¸é‡é»', 'å­¸æ ¡ç‰¹è‰²', 'æ ¡é¢¨', 'è¾¦å­¸å®—æ—¨', 'å…¨æ–¹ä½å­¸ç¿’']
    existing_feature_columns = [col for col in text_columns_for_features if col in df.columns]
    df['features_text'] = df[existing_feature_columns].fillna('').astype(str).agg(' '.join, axis=1)
    
    percentage_cols = {
        'ä¸Šå­¸å¹´å·²æ¥å—å¸«è³‡åŸ¹è¨“äººæ•¸ç™¾åˆ†ç‡': 'å·²æ¥å—å¸«è³‡åŸ¹è¨“(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)',
        'ä¸Šå­¸å¹´å­¸å£«äººæ•¸ç™¾åˆ†ç‡': 'å­¸å£«(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)',
        'ä¸Šå­¸å¹´ç¢©å£«_åšå£«æˆ–ä»¥ä¸Šäººæ•¸ç™¾åˆ†ç‡': 'ç¢©å£«ã€åšå£«æˆ–ä»¥ä¸Š (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)',
        'ä¸Šå­¸å¹´ç‰¹æ®Šæ•™è‚²åŸ¹è¨“äººæ•¸ç™¾åˆ†ç‡': 'ç‰¹æ®Šæ•™è‚²åŸ¹è¨“ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)',
        'ä¸Šå­¸å¹´0è‡³4å¹´å¹´è³‡äººæ•¸ç™¾åˆ†ç‡': '0-4å¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)',
        'ä¸Šå­¸å¹´5è‡³9å¹´å¹´è³‡äººæ•¸ç™¾åˆ†ç‡': '5-9å¹´è³‡(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)',
        'ä¸Šå­¸å¹´10å¹´å¹´è³‡æˆ–ä»¥ä¸Šäººæ•¸ç™¾åˆ†ç‡': '10å¹´æˆ–ä»¥ä¸Šå¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)'
    }
    for new_col, old_col_name in percentage_cols.items():
        if new_col in df.columns:
            s = pd.to_numeric(df[new_col].astype(str).str.replace('%', '', regex=False), errors='coerce').fillna(0)
            df[old_col_name] = s.round(1)
            
    df['p1_no_exam_assessment'] = df['å°ä¸€ä¸Šå­¸æœŸæ¸¬è€ƒ'].apply(lambda x: 'æ˜¯' if str(x).strip() == 'æœ‰' else 'å¦') if 'å°ä¸€ä¸Šå­¸æœŸæ¸¬è€ƒ' in df.columns else 'å¦'
    df['avoid_holiday_exams'] = df['é•·å‡æœŸå¾Œæ¸¬è€ƒ'].apply(lambda x: 'æ˜¯' if str(x).strip() == 'æ²’æœ‰' else 'å¦') if 'é•·å‡æœŸå¾Œæ¸¬è€ƒ' in df.columns else 'å¦'
    df['afternoon_tutorial'] = df['ä¸‹åˆå®¶èª²è¼”å°'].apply(lambda x: 'æ˜¯' if str(x).strip() == 'æœ‰' else 'å¦') if 'ä¸‹åˆå®¶èª²è¼”å°' in df.columns else 'å¦'
    df['has_pta'] = df['å®¶é•·æ•™å¸«æœƒ'].apply(lambda x: 'æ˜¯' if str(x).strip() == 'æœ‰' else 'å¦') if 'å®¶é•·æ•™å¸«æœƒ' in df.columns else 'å¦'
    
    if 'å­¸æ ¡é¡åˆ¥1' in df.columns:
        def standardize_category(cat):
            cat_str = str(cat)
            if 'å®˜ç«‹' in cat_str: return 'å®˜ç«‹'
            if 'ç›´è³‡' in cat_str: return 'ç›´è³‡'
            if 'è³‡åŠ©' in cat_str: return 'è³‡åŠ©'
            if 'ç§ç«‹' in cat_str: return 'ç§ç«‹'
            return cat
        df['å­¸æ ¡é¡åˆ¥'] = df['å­¸æ ¡é¡åˆ¥1'].apply(standardize_category)
    else:
        df['å­¸æ ¡é¡åˆ¥'] = 'æœªæä¾›'

    has_bus = df['æ ¡è»Š'].astype(str).str.strip() == 'æœ‰' if 'æ ¡è»Š' in df.columns else pd.Series(False, index=df.index)
    has_nanny = df['ä¿å§†è»Š'].astype(str).str.strip() == 'æœ‰' if 'ä¿å§†è»Š' in df.columns else pd.Series(False, index=df.index)
    df['has_school_bus'] = 'å¦'
    df.loc[has_bus | has_nanny, 'has_school_bus'] = 'æ˜¯'
    df['bus_service_text'] = 'æ²’æœ‰'
    df.loc[has_bus & has_nanny, 'bus_service_text'] = 'æœ‰æ ¡è»ŠåŠä¿å§†è»Š'
    df.loc[has_bus & ~has_nanny, 'bus_service_text'] = 'æœ‰æ ¡è»Š'
    df.loc[~has_bus & has_nanny, 'bus_service_text'] = 'æœ‰ä¿å§†è»Š'
    
    feeder_cols = ['ä¸€æ¢é¾ä¸­å­¸', 'ç›´å±¬ä¸­å­¸', 'è¯ç¹«ä¸­å­¸']
    existing_feeder_cols = [col for col in feeder_cols if col in df.columns]
    if existing_feeder_cols:
         df['has_feeder_school'] = df[existing_feeder_cols].apply(
            lambda row: 'æ˜¯' if any(pd.notna(val) and str(val).strip() not in ['', 'æ²’æœ‰'] for val in row) else 'å¦',
            axis=1
        )
    else:
        df['has_feeder_school'] = 'å¦'
    return df

# --- ä¸»è¦æ‡‰ç”¨ç¨‹å¼é‚è¼¯ ---
try:
    # --- ä¿®æ”¹ï¼šå·²æ›ä¸Šæ‚¨æœ€æ–°çš„ database.xlsx çš„ Raw URL ---
    DATA_URL = "https://raw.githubusercontent.com/kingyeung625/hk-school-selector/main/database.xlsx"
    
    main_dataframe = pd.read_excel(DATA_URL, sheet_name='å­¸æ ¡è³‡æ–™', engine='openpyxl')
    
    articles_dataframe = None
    try:
        articles_dataframe = pd.read_excel(DATA_URL, sheet_name='ç›¸é—œæ–‡ç« ', engine='openpyxl')
    except Exception:
        st.info("æç¤ºï¼šåœ¨ Excel æª”æ¡ˆä¸­æ‰¾ä¸åˆ°åç‚ºã€Œç›¸é—œæ–‡ç« ã€çš„å·¥ä½œè¡¨ã€‚")

    net_dataframe = None
    try:
        net_dataframe = pd.read_excel(DATA_URL, sheet_name='æ ¡ç¶²è³‡æ–™', engine='openpyxl')
    except Exception:
        st.info("æç¤ºï¼šåœ¨ Excel æª”æ¡ˆä¸­æ‰¾ä¸åˆ°åç‚ºã€Œæ ¡ç¶²è³‡æ–™ã€çš„å·¥ä½œè¡¨ã€‚")


    processed_df = process_dataframe(main_dataframe, articles_dataframe, net_dataframe)
    
    active_filters = []
    with st.expander("ğŸ“ æŒ‰å­¸æ ¡åç¨±æœå°‹", expanded=True):
        search_keyword = st.text_input("**è¼¸å…¥å­¸æ ¡åç¨±é—œéµå­—ï¼š**", key="name_search")
        if search_keyword: active_filters.append(('name', search_keyword))
    with st.expander("â„¹ï¸ æŒ‰å­¸æ ¡åŸºæœ¬è³‡æ–™æœå°‹", expanded=True):
        col1, col2, col3 = st.columns(3)
        with col1:
            if 'å­¸æ ¡é¡åˆ¥' in processed_df.columns:
                cat_options = sorted(processed_df['å­¸æ ¡é¡åˆ¥'].dropna().unique())
                selected_cats = st.multiselect("å­¸æ ¡é¡åˆ¥", options=cat_options, key="category_select")
                if selected_cats: active_filters.append(('category', selected_cats))
            if 'å­¸ç”Ÿæ€§åˆ¥' in processed_df.columns:
                gender_options = sorted(processed_df['å­¸ç”Ÿæ€§åˆ¥'].dropna().unique())
                selected_genders = st.multiselect("å­¸ç”Ÿæ€§åˆ¥", options=gender_options, key="gender_select")
                if selected_genders: active_filters.append(('gender', selected_genders))
        with col2:
            if 'å®—æ•™' in processed_df.columns:
                religion_options = sorted(processed_df['å®—æ•™'].dropna().unique())
                selected_religions = st.multiselect("å®—æ•™", options=religion_options, key="religion_select")
                if selected_religions: active_filters.append(('religion', selected_religions))
            if 'æ•™å­¸èªè¨€' in processed_df.columns:
                lang_options = ['ä¸é™'] + sorted(processed_df['æ•™å­¸èªè¨€'].dropna().unique())
                selected_lang = st.selectbox("æ•™è‚²èªè¨€", options=lang_options, key="language_select")
                if selected_lang != 'ä¸é™': active_filters.append(('language', selected_lang))
        with col3:
            if 'è¾¦å­¸åœ˜é«”' in processed_df.columns:
                body_counts = processed_df['è¾¦å­¸åœ˜é«”'].value_counts()
                body_df = body_counts.reset_index()
                body_df.columns = ['è¾¦å­¸åœ˜é«”', 'count']
                body_df_sorted = body_df.sort_values(by=['count', 'è¾¦å­¸åœ˜é«”'], ascending=[False, True])
                
                formatted_body_options = [ f"{row['è¾¦å­¸åœ˜é«”']} ({row['count']})" for index, row in body_df_sorted.iterrows()]
                selected_formatted_bodies = st.multiselect("è¾¦å­¸åœ˜é«”", options=formatted_body_options, key="body_select")
                
                if selected_formatted_bodies:
                    original_body_names = [item.rsplit(' (', 1)[0] for item in selected_formatted_bodies]
                    active_filters.append(('body', original_body_names))
            
            feeder_choice = st.radio("æœ‰é—œè¯ä¸­å­¸ï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True, key='feeder')
            if feeder_choice != 'ä¸é™': active_filters.append(('feeder', feeder_choice))
            
            bus_choice = st.radio("æœ‰æ ¡è»Šæˆ–ä¿å§†è»Šæœå‹™ï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True, key='bus')
            if bus_choice != 'ä¸é™': active_filters.append(('bus', bus_choice))
            
    with st.expander("ğŸ“ æŒ‰åœ°å€åŠæ ¡ç¶²æœå°‹", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            all_districts = sorted(processed_df['åœ°å€'].dropna().unique()); selected_districts = st.multiselect("**é¸æ“‡åœ°å€ (å¯å¤šé¸)**", options=all_districts, key="district_select")
            if selected_districts: active_filters.append(('district', selected_districts))
        with col2:
            if 'æ ¡ç¶²' in processed_df.columns:
                net_df = processed_df[processed_df['åœ°å€'].isin(selected_districts)] if selected_districts else processed_df
                available_nets = sorted(net_df['æ ¡ç¶²'].dropna().unique())
                selected_nets = st.multiselect("**é¸æ“‡æ ¡ç¶² (å¯å¤šé¸)**", options=available_nets, key="net_select")
                if selected_nets: active_filters.append(('net', selected_nets))

    st.markdown('<div style="border: 2px dashed #cccccc; padding: 20px; text-align: center; margin-top: 20px; margin-bottom: 20px;">å»£å‘Šç©ºé–“</div>', unsafe_allow_html=True)

    with st.expander("ğŸŒŸ æŒ‰è¾¦å­¸ç‰¹è‰²æœå°‹", expanded=False):
        full_search_term = st.text_input("è¼¸å…¥ä»»ä½•é—œéµå­—æœå°‹å…¨æ ¡è³‡æ–™ (ä¾‹å¦‚ï¼šå¥§æ•¸ã€é¢è©¦ç­):", key="full_text_search")
        if full_search_term:
            active_filters.append(('full_text', full_search_term))
        st.markdown("---")
        st.markdown("**æŒ‰é è¨­æ¨™ç±¤ç¯©é¸ï¼š**")

        feature_mapping = {"ã€æ•™å­¸æ¨¡å¼èˆ‡é‡é»ã€‘": {"è‡ªä¸»å­¸ç¿’åŠæ¢ç©¶": ['è‡ªä¸»å­¸ç¿’', 'æ¢ç©¶'],"STEAM": ['STEAM', 'å‰µå®¢'], "é›»å­å­¸ç¿’": ['é›»å­å­¸ç¿’', 'e-learning'], "é–±è®€": ['é–±è®€'], "è³‡å„ªæ•™è‚²": ['è³‡å„ª'], "å°ˆé¡Œç ”ç¿’": ['å°ˆé¡Œç ”ç¿’'], "è·¨èª²ç¨‹å­¸ç¿’": ['è·¨èª²ç¨‹'], "å…©æ–‡ä¸‰èª": ['å…©æ–‡ä¸‰èª'], "è‹±æ–‡æ•™è‚²": ['è‹±æ–‡'], "å®¶æ ¡åˆä½œ": ['å®¶æ ¡åˆä½œ'], "å¢ƒå¤–äº¤æµ": ['å¢ƒå¤–äº¤æµ'], "è—è¡“": ['è—è¡“'], "é«”è‚²": ['é«”è‚²']},"ã€åƒ¹å€¼è§€èˆ‡å“å¾·ã€‘": {"ä¸­è¯æ–‡åŒ–æ•™è‚²": ['ä¸­è¯æ–‡åŒ–'], "æ­£å‘ã€åƒ¹å€¼è§€ã€ç”Ÿå‘½æ•™è‚²": ['æ­£å‘', 'åƒ¹å€¼è§€', 'ç”Ÿå‘½æ•™è‚²'], "åœ‹æ°‘æ•™è‚²ã€åœ‹å®‰æ•™è‚²": ['åœ‹æ°‘', 'åœ‹å®‰'], "æœå‹™æ•™è‚²": ['æœå‹™'], "é—œæ„›åŠç²¾ç¥å¥åº·": ['é—œæ„›', 'å¥åº·']},"ã€å­¸ç”Ÿæ”¯æ´èˆ‡ç™¼å±•ã€‘": {"å…¨äººç™¼å±•": ['å…¨äººç™¼å±•', 'å¤šå…ƒç™¼å±•'], "ç”Ÿæ¶¯è¦åŠƒã€å•Ÿç™¼æ½›èƒ½": ['ç”Ÿæ¶¯è¦åŠƒ', 'æ½›èƒ½'], "æ‹”å°–è£œåº•ã€ç…§é¡§å·®ç•°": ['æ‹”å°–è£œåº•', 'å€‹åˆ¥å·®ç•°'], "èåˆæ•™è‚²": ['èåˆæ•™è‚²']}}
        col1, col2, col3 = st.columns(3); all_selected_options = []
        with col1: selected1 = st.multiselect("æ•™å­¸æ¨¡å¼èˆ‡é‡é»", options=list(feature_mapping["ã€æ•™å­¸æ¨¡å¼èˆ‡é‡é»ã€‘"].keys()), key="features1"); all_selected_options.extend(selected1)
        with col2: selected2 = st.multiselect("åƒ¹å€¼è§€èˆ‡å“å¾·", options=list(feature_mapping["ã€åƒ¹å€¼è§€èˆ‡å“å¾·ã€‘"].keys()), key="features2"); all_selected_options.extend(selected2)
        with col3: selected3 = st.multiselect("å­¸ç”Ÿæ”¯æ´èˆ‡ç™¼å±•", options=list(feature_mapping["ã€å­¸ç”Ÿæ”¯æ´èˆ‡ç™¼å±•ã€‘"].keys()), key="features3"); all_selected_options.extend(selected3)
        if all_selected_options: active_filters.append(('features', all_selected_options))
    
    with st.expander("ğŸ“ æŒ‰å¸«è³‡æ¢ä»¶æœå°‹", expanded=False):
        col1, col2, col3 = st.columns(3)
        with col1:
            col1_sliders = {'å·²æ¥å—å¸«è³‡åŸ¹è¨“(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'å¸«è³‡åŸ¹è¨“æ¯”ä¾‹ (%)', 'å­¸å£«(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'å­¸å£«å­¸æ­·æ¯”ä¾‹ (%)', 'ç¢©å£«ã€åšå£«æˆ–ä»¥ä¸Š (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'ç¢©å£«æˆ–ä»¥ä¸Šå­¸æ­·æ¯”ä¾‹ (%)'}
            for col_name, slider_label in col1_sliders.items():
                if col_name in processed_df.columns:
                    min_val = st.slider(slider_label, 0, 100, 0, 5, key=col_name)
                    if min_val > 0: active_filters.append(('slider', (col_name, min_val)))
        with col2:
            col2_sliders = {'0-4å¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': '0-4å¹´è³‡æ¯”ä¾‹ (%)', '5-9å¹´è³‡(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': '5-9å¹´è³‡æ¯”ä¾‹ (%)', '10å¹´æˆ–ä»¥ä¸Šå¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': '10å¹´ä»¥ä¸Šå¹´è³‡æ¯”ä¾‹ (%)'}
            for col_name, slider_label in col2_sliders.items():
                if col_name in processed_df.columns:
                    min_val = st.slider(slider_label, 0, 100, 0, 5, key=col_name)
                    if min_val > 0: active_filters.append(('slider', (col_name, min_val)))
        with col3:
            col3_sliders = {'ç‰¹æ®Šæ•™è‚²åŸ¹è¨“ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)': 'ç‰¹æ®Šæ•™è‚²åŸ¹è¨“æ¯”ä¾‹ (%)'}
            for col_name, slider_label in col3_sliders.items():
                if col_name in processed_df.columns:
                    min_val = st.slider(slider_label, 0, 100, 0, 5, key=col_name)
                    if min_val > 0: active_filters.append(('slider', (col_name, min_val)))

    with st.expander("ğŸ“š æŒ‰èª²æ¥­å®‰æ’æœå°‹", expanded=False):
        st.markdown("**è©•ä¼°æ¬¡æ•¸**"); col1, col2 = st.columns(2)
        with col1:
            max_p1_tests = st.selectbox('å°ä¸€å…¨å¹´æœ€å¤šæ¸¬é©—æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3, 4], index=0, key='p1_test')
            if max_p1_tests != 'ä»»ä½•æ¬¡æ•¸': active_filters.append(('max_p1_tests', max_p1_tests))
            max_p2_6_tests = st.selectbox('å°äºŒè‡³å…­å…¨å¹´æœ€å¤šæ¸¬é©—æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3, 4], index=0, key='p2-6_test')
            if max_p2_6_tests != 'ä»»ä½•æ¬¡æ•¸': active_filters.append(('max_p2_6_tests', max_p2_6_tests))
        with col2:
            max_p1_exams = st.selectbox('å°ä¸€å…¨å¹´æœ€å¤šè€ƒè©¦æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3], index=0, key='p1_exam')
            if max_p1_exams != 'ä»»ä½•æ¬¡æ•¸': active_filters.append(('max_p1_exams', max_p1_exams))
            max_p2_6_exams = st.selectbox('äºŒè‡³å…­å¹´ç´šæœ€å¤šè€ƒè©¦æ¬¡æ•¸', options=['ä»»ä½•æ¬¡æ•¸', 0, 1, 2, 3, 4], index=0, key='p2-6_exam')
            if max_p2_6_exams != 'ä»»ä½•æ¬¡æ•¸': active_filters.append(('max_p2_6_exams', max_p2_6_exams))
        st.markdown("**å…¶ä»–å®‰æ’**"); p1_no_exam = st.radio("å°ä¸€ä¸Šå­¸æœŸä»¥å¤šå…ƒåŒ–è©•ä¼°ä»£æ›¿æ¸¬è€ƒï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True, key="p1_no_exam_radio")
        if p1_no_exam != 'ä¸é™': active_filters.append(('p1_no_exam', p1_no_exam))
        avoid_holiday = st.radio("é¿å…é•·å‡å¾Œæ¸¬è€ƒï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True, key='holiday')
        if avoid_holiday != 'ä¸é™': active_filters.append(('avoid_holiday', avoid_holiday))
        afternoon_tut = st.radio("è¨­ä¸‹åˆå°ä¿®æ™‚æ®µï¼Ÿ", ['ä¸é™', 'æ˜¯', 'å¦'], horizontal=True, key='tutorial')
        if afternoon_tut != 'ä¸é™': active_filters.append(('afternoon_tut', afternoon_tut))
    
    def reset_filters():
        keys_to_reset = [ "name_search", "category_select", "gender_select", "religion_select", "language_select", "body_select", "feeder", "bus", "district_select", "net_select", "full_text_search", "features1", "features2", "features3", "p1_test", "p2-6_test", "p1_exam", "p2-6_exam", "p1_no_exam_radio", "holiday", "tutorial"]
        slider_key_names = list(percentage_cols.values())
        keys_to_reset.extend(slider_key_names)
        for key in keys_to_reset:
            if key in st.session_state:
                del st.session_state[key]
        st.session_state.page = 0
    
    st.button("é‡è¨­æœå°‹å™¨", on_click=reset_filters, key="reset_button_top")
    
    if active_filters != st.session_state.get('active_filters_cache', None):
        st.session_state.page = 0
        st.session_state.active_filters_cache = active_filters

    st.markdown("---"); st.header(f"æœå°‹çµæœ")
    if not active_filters:
        st.info("â˜ï¸ è«‹ä½¿ç”¨ä¸Šæ–¹çš„ç¯©é¸å™¨é–‹å§‹å°‹æ‰¾å­¸æ ¡ã€‚")
    else:
        filtered_df = processed_df.copy()
        all_selected_keywords_for_highlight = []
        for filter_type, value in active_filters:
            if filter_type == 'name': filtered_df = filtered_df[filtered_df['å­¸æ ¡åç¨±'].str.contains(value, case=False, na=False)]
            elif filter_type == 'category': filtered_df = filtered_df[filtered_df['å­¸æ ¡é¡åˆ¥'].isin(value)]
            elif filter_type == 'gender': filtered_df = filtered_df[filtered_df['å­¸ç”Ÿæ€§åˆ¥'].isin(value)]
            elif filter_type == 'religion': filtered_df = filtered_df[filtered_df['å®—æ•™'].isin(value)]
            elif filter_type == 'language': filtered_df = filtered_df[filtered_df['æ•™å­¸èªè¨€'] == value]
            elif filter_type == 'body': filtered_df = filtered_df[filtered_df['è¾¦å­¸åœ˜é«”'].isin(value)]
            elif filter_type == 'feeder': filtered_df = filtered_df[filtered_df['has_feeder_school'] == value]
            elif filter_type == 'bus': filtered_df = filtered_df[filtered_df['has_school_bus'] == value]
            elif filter_type == 'full_text':
                filtered_df = filtered_df[filtered_df['full_text_search'].str.contains(value, case=False, na=False)]
                all_selected_keywords_for_highlight.append(value)
            elif filter_type == 'district': filtered_df = filtered_df[filtered_df['åœ°å€'].isin(value)]
            elif filter_type == 'net': filtered_df = filtered_df[filtered_df['æ ¡ç¶²'].isin(value)]
            elif filter_type == 'features':
                for option in value:
                    search_terms = [];
                    for category in feature_mapping.values():
                        if option in category: search_terms = category[option]; all_selected_keywords_for_highlight.append(search_terms); break
                    if search_terms:
                        regex_pattern = '|'.join([re.escape(term) for term in search_terms])
                        filtered_df = filtered_df[filtered_df['features_text'].str.contains(regex_pattern, case=False, na=False, regex=True)]
            elif filter_type == 'slider':
                col_name, min_val = value; 
                if col_name in filtered_df.columns:
                    filtered_df = filtered_df[filtered_df[col_name] >= min_val]
            elif filter_type == 'max_p1_tests': filtered_df = filtered_df[filtered_df['å°ä¸€å…¨å¹´æ¸¬é©—æ¬¡æ•¸'] <= int(value)]
            elif filter_type == 'max_p2_6_tests': filtered_df = filtered_df[filtered_df['å°äºŒè‡³å°å…­å…¨å¹´æ¸¬é©—æ¬¡æ•¸'] <= int(value)]
            elif filter_type == 'max_p1_exams': filtered_df = filtered_df[filtered_df['å°ä¸€å…¨å¹´è€ƒè©¦æ¬¡æ•¸'] <= int(value)]
            elif filter_type == 'max_p2_6_exams': filtered_df = filtered_df[filtered_df['å°äºŒè‡³å°å…­å…¨å¹´è€ƒè©¦æ¬¡æ•¸'] <= int(value)]
            elif filter_type == 'p1_no_exam': filtered_df = filtered_df[filtered_df['p1_no_exam_assessment'] == value]
            elif filter_type == 'avoid_holiday': filtered_df = filtered_df[filtered_df['avoid_holiday_exams'] == value]
            elif filter_type == 'afternoon_tut': filtered_df = filtered_df[filtered_df['afternoon_tutorial'] == value]
        
        st.video("https://www.youtube.com/watch?v=5LNrTnWvuho")
        st.info(f"ç¶œåˆæ‰€æœ‰æ¢ä»¶ï¼Œå…±æ‰¾åˆ° {len(filtered_df)} æ‰€å­¸æ ¡ã€‚")
        
        if not filtered_df.empty:
            ITEMS_PER_PAGE = 10
            total_items = len(filtered_df)
            total_pages = (total_items + ITEMS_PER_PAGE - 1) // ITEMS_PER_PAGE
            st.session_state.page = max(0, min(st.session_state.page, total_pages - 1))
            
            start_idx = st.session_state.page * ITEMS_PER_PAGE
            end_idx = min(start_idx + ITEMS_PER_PAGE, total_items)
            
            page_df = filtered_df.iloc[start_idx:end_idx]
            
            for index, school in page_df.iterrows():
                with st.expander(f"**{school.get('å­¸æ ¡åç¨±', 'N/A')}** ({school.get('åœ°å€', 'N/A')})"):
                    articles = school.get('articles', [])
                    if articles:
                        st.markdown("#### ğŸ“– ç›¸é—œå ±å°")
                        for title, url in articles:
                            image_url = get_article_metadata(url)
                            if image_url:
                                st.markdown(f'<a href="{url}" target="_blank"><img src="{image_url}" alt="{title}" style="width:100%; max-width:400px; border-radius: 8px; margin-bottom: 5px;"></a>', unsafe_allow_html=True)
                                st.markdown(f'**<a href="{url}" target="_blank" style="text-decoration: none; color: #333;">{title}</a>**', unsafe_allow_html=True)
                            else:
                                st.markdown(f"- [{title}]({url})")
                        st.markdown("---")

                    st.markdown("#### ğŸ“– å­¸æ ¡åŸºæœ¬è³‡æ–™")
                    info_col1, info_col2 = st.columns(2)
                    with info_col1:
                        st.write(f"**å­¸æ ¡é¡åˆ¥:** {school.get('å­¸æ ¡é¡åˆ¥', 'æœªæä¾›')}")
                        st.write(f"**è¾¦å­¸åœ˜é«”:** {school.get('è¾¦å­¸åœ˜é«”', 'æœªæä¾›')}")
                        st.write(f"**å‰µæ ¡å¹´ä»½:** {school.get('å‰µæ ¡å¹´ä»½', 'æœªæä¾›')}")
                        st.write(f"**æ ¡é•·:** {school.get('æ ¡é•·å§“å', 'æœªæä¾›')}")
                        st.write(f"**æ•™å­¸èªè¨€:** {school.get('æ•™å­¸èªè¨€', 'æœªæä¾›')}")
                    with info_col2:
                        st.write(f"**å­¸ç”Ÿæ€§åˆ¥:** {school.get('å­¸ç”Ÿæ€§åˆ¥', 'æœªæä¾›')}")
                        st.write(f"**å®—æ•™:** {school.get('å®—æ•™', 'æœªæä¾›')}")
                        st.write(f"**æ ¡ç¶²:** {school.get('æ ¡ç¶²', 'æœªæä¾›')}")
                        st.write(f"**æ ¡ç›£:** {school.get('æ ¡ç›£_æ ¡ç®¡æœƒä¸»å¸­å§“å', 'æœªæä¾›')}")
                        st.write(f"**å®¶æ•™æœƒ:** {school.get('has_pta', 'æœªæä¾›')}")

                    st.write(f"**å­¸æ ¡ä½”åœ°é¢ç©:** {school.get('å­¸æ ¡ä½”åœ°é¢ç©', 'æœªæä¾›')}")
                    st.write(f"**æ ¡è»Šæœå‹™:** {school.get('bus_service_text', 'æ²’æœ‰')}")
                    
                    feeder_schools = {"ä¸€æ¢é¾ä¸­å­¸": school.get('ä¸€æ¢é¾ä¸­å­¸'), "ç›´å±¬ä¸­å­¸": school.get('ç›´å±¬ä¸­å­¸'), "è¯ç¹«ä¸­å­¸": school.get('è¯ç¹«ä¸­å­¸')}
                    for title, value in feeder_schools.items():
                        if pd.notna(value) and str(value).strip() not in ['', 'æ²’æœ‰']: st.write(f"**{title}:** {value}")
                    
                    st.markdown(
                        '<div style="border: 2px dashed #cccccc; padding: 15px; text-align: center; margin-top: 15px; margin-bottom: 15px;">å»£å‘Šç©ºé–“</div>',
                        unsafe_allow_html=True
                    )
                    
                    st.markdown("---")
                    st.markdown("#### ğŸ« å­¸æ ¡è¨­æ–½è©³æƒ…")
                    facility_counts = (f"ğŸ« èª²å®¤: {school.get('èª²å®¤æ•¸ç›®', 'N/A')} | ğŸ›ï¸ ç¦®å ‚: {school.get('ç¦®å ‚æ•¸ç›®', 'N/A')} | ğŸ¤¸ æ“å ´: {school.get('æ“å ´æ•¸ç›®', 'N/A')} | ğŸ“š åœ–æ›¸é¤¨: {school.get('åœ–æ›¸é¤¨æ•¸ç›®', 'N/A')}")
                    st.markdown(facility_counts)
                    other_facilities = {"ç‰¹åˆ¥å®¤": "ç‰¹åˆ¥å®¤", "æ”¯æ´æœ‰ç‰¹æ®Šæ•™è‚²éœ€è¦å­¸ç”Ÿçš„è¨­æ–½": "æ”¯æ´æœ‰ç‰¹æ®Šæ•™è‚²éœ€è¦å­¸ç”Ÿçš„è¨­æ–½", "å…¶ä»–å­¸æ ¡è¨­æ–½": "å…¶ä»–å­¸æ ¡è¨­æ–½"}
                    for column_name, display_title in other_facilities.items():
                        detail_value = school.get(column_name, '');
                        if pd.notna(detail_value) and str(detail_value).strip() not in ['', 'æ²’æœ‰']: st.write(f"**{display_title}:** {detail_value}")
                    
                    st.markdown("---")
                    st.markdown("#### ğŸ§‘â€ğŸ« å¸«è³‡åœ˜éšŠæ¦‚è¦½")
                    approved_teachers = school.get('ä¸Šå­¸å¹´æ ¸å‡†ç·¨åˆ¶æ•™å¸«è·ä½æ•¸ç›®')
                    total_teachers = school.get('ä¸Šå­¸å¹´æ•™å¸«ç¸½äººæ•¸')
                    col1, col2 = st.columns(2)
                    with col1:
                        if pd.isna(approved_teachers):
                            st.metric("æ ¸å‡†ç·¨åˆ¶æ•™å¸«è·ä½", "æ²’æœ‰è³‡æ–™")
                        else:
                            st.metric("æ ¸å‡†ç·¨åˆ¶æ•™å¸«è·ä½", f"{int(approved_teachers)} äºº")
                    with col2:
                        if pd.isna(total_teachers):
                            st.metric("å…¨æ ¡æ•™å¸«ç¸½äººæ•¸", "æ²’æœ‰è³‡æ–™")
                        else:
                            if not pd.isna(approved_teachers):
                                diff = total_teachers - approved_teachers
                                if diff >= 0:
                                    st.metric("å…¨æ ¡æ•™å¸«ç¸½äººæ•¸", f"{int(total_teachers)} äºº", f"+{int(diff)}", delta_color="normal")
                                else:
                                    st.metric("å…¨æ ¡æ•™å¸«ç¸½äººæ•¸", f"{int(total_teachers)} äºº", f"{int(diff)}", delta_color="inverse")
                            else:
                                st.metric("å…¨æ ¡æ•™å¸«ç¸½äººæ•¸", f"{int(total_teachers)} äºº")
                    if st.button("ğŸ“Š é¡¯ç¤ºå¸«è³‡æ¯”ä¾‹åœ–è¡¨", key=f"chart_btn_{index}"):
                        st.markdown("#### ğŸ“Š å¸«è³‡æ¯”ä¾‹åˆ†ä½ˆåœ–"); pie_col1, pie_col2 = st.columns(2)
                        with pie_col1:
                            st.markdown("**å­¸æ­·åˆ†ä½ˆ**"); edu_data = {'é¡åˆ¥': ['å­¸å£«', 'ç¢©å£«æˆ–ä»¥ä¸Š'],'æ¯”ä¾‹': [school.get('å­¸å£«(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0), school.get('ç¢©å£«ã€åšå£«æˆ–ä»¥ä¸Š (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0)]}; edu_df = pd.DataFrame(edu_data)
                            if edu_df['æ¯”ä¾‹'].sum() > 0:
                                fig1 = px.pie(edu_df, values='æ¯”ä¾‹', names='é¡åˆ¥', color_discrete_sequence=px.colors.sequential.Greens_r)
                                fig1.update_layout(showlegend=False, margin=dict(l=70, r=70, t=40, b=40), height=380, font=dict(size=16), uniformtext_minsize=14, uniformtext_mode='hide')
                                fig1.update_traces(textposition='inside', textinfo='percent+label', textfont_color='white'); st.plotly_chart(fig1, use_container_width=True, key=f"edu_pie_{index}")
                            else: st.text("ç„¡ç›¸é—œæ•¸æ“š")
                        with pie_col2:
                            st.markdown("**å¹´è³‡åˆ†ä½ˆ**"); exp_data = {'é¡åˆ¥': ['0-4å¹´', '5-9å¹´', '10å¹´ä»¥ä¸Š'],'æ¯”ä¾‹': [school.get('0-4å¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0), school.get('5-9å¹´è³‡(ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0), school.get('10å¹´æˆ–ä»¥ä¸Šå¹´è³‡ (ä½”å…¨æ ¡æ•™å¸«äººæ•¸%)', 0)]}; exp_df = pd.DataFrame(exp_data)
                            if exp_df['æ¯”ä¾‹'].sum() > 0:
                                fig2 = px.pie(exp_df, values='æ¯”ä¾‹', names='é¡åˆ¥', color_discrete_sequence=px.colors.sequential.Blues_r)
                                fig2.update_layout(showlegend=False, margin=dict(l=70, r=70, t=40, b=40), height=380, font=dict(size=16), uniformtext_minsize=14, uniformtext_mode='hide')
                                fig2.update_traces(textposition='inside', textinfo='percent+label', textfont_color='white'); st.plotly_chart(fig2, use_container_width=True, key=f"exp_pie_{index}")
                            else: st.text("ç„¡ç›¸é—œæ•¸æ“š")
                    
                    st.markdown(
                        '<div style="border: 2px dashed #cccccc; padding: 15px; text-align: center; margin-top: 15px; margin-bottom: 15px;">å»£å‘Šç©ºé–“</div>',
                        unsafe_allow_html=True
                    )

                    st.markdown("---")
                    st.markdown("#### ğŸ“š èª²æ¥­èˆ‡è©•ä¼°å®‰æ’")
                    homework_details = {"å°ä¸€æ¸¬é©—/è€ƒè©¦æ¬¡æ•¸": f"{school.get('å°ä¸€å…¨å¹´æ¸¬é©—æ¬¡æ•¸', 'N/A')} / {school.get('å°ä¸€å…¨å¹´è€ƒè©¦æ¬¡æ•¸', 'N/A')}", "é«˜å¹´ç´šæ¸¬é©—/è€ƒè©¦æ¬¡æ•¸": f"{school.get('å°äºŒè‡³å°å…­å…¨å¹´æ¸¬é©—æ¬¡æ•¸', 'N/A')} / {school.get('å°äºŒè‡³å°å…­å…¨å¹´è€ƒè©¦æ¬¡æ•¸', 'N/A')}", "å°ä¸€å…è©¦è©•ä¼°": school.get('p1_no_exam_assessment', 'N/A'), "å¤šå…ƒå­¸ç¿’è©•ä¼°": school.get('å¤šå…ƒå­¸ç¿’è©•ä¼°', 'æœªæä¾›'), "é¿å…é•·å‡å¾Œæ¸¬è€ƒ": school.get('avoid_holiday_exams', 'N/A'), "ä¸‹åˆå°ä¿®æ™‚æ®µ": school.get('afternoon_tutorial', 'N/A')}
                    for title, value in homework_details.items():
                        if pd.notna(value) and str(value).strip() != '': st.write(f"**{title}:** {value}")
                    
                    st.markdown("---")
                    st.markdown("#### âœ¨ è¾¦å­¸ç‰¹è‰²èˆ‡ç™¼å±•è¨ˆåŠƒ")
                    feature_text_map = {"å­¸æ ¡ç™¼å±•è¨ˆåŠƒ": "å­¸æ ¡ç™¼å±•è¨ˆåŠƒ", "å­¸ç¿’å’Œæ•™å­¸é‡é»": "å­¸ç¿’å’Œæ•™å­¸é‡é»", "å­¸æ ¡ç‰¹è‰²": "å­¸æ ¡ç‰¹è‰²"}
                    for column_name, display_title in feature_text_map.items():
                        detail_value = school.get(column_name, '')
                        if pd.notna(detail_value) and str(detail_value).strip() not in ['', 'æ²’æœ‰']:
                            should_expand = False
                            if all_selected_keywords_for_highlight:
                                text_to_check = str(detail_value).lower()
                                flat_keywords = []
                                for item in all_selected_keywords_for_highlight:
                                    if isinstance(item, list):
                                        flat_keywords.extend(item)
                                    else:
                                        flat_keywords.append(item)
                                if any(keyword.lower() in text_to_check for keyword in flat_keywords):
                                    should_expand = True
                            
                            with st.expander(f"**{display_title}**", expanded=should_expand):
                                formatted_content = format_and_highlight_text(detail_value, all_selected_keywords_for_highlight)
                                st.markdown(formatted_content, unsafe_allow_html=True)

                        if column_name == 'å­¸æ ¡ç‰¹è‰²': # Example of specific placement
                            st.markdown(
                                '<div style="border: 2px dashed #cccccc; padding: 15px; text-align: center; margin-top: 15px; margin-bottom: 15px;">å»£å‘Šç©ºé–“</div>',
                                unsafe_allow_html=True
                            )
                    
                    st.markdown(
                        '<div style="border: 2px dashed #cccccc; padding: 15px; text-align: center; margin-top: 15px; margin-bottom: 15px;">å»£å‘Šç©ºé–“</div>',
                        unsafe_allow_html=True
                    )

            st.markdown("---")
            col1, col2, col3 = st.columns([1, 1, 1])
            with col1:
                st.button("é‡è¨­æœå°‹å™¨", on_click=reset_filters, key="reset_button_bottom")
            
            if total_pages > 1:
                page_selection_col, next_button_col = st.columns([2,1])
                with page_selection_col:
                    page_options = [f"ç¬¬ {i+1} é " for i in range(total_pages)]
                    current_page_label = f"ç¬¬ {st.session_state.page + 1} é "
                    new_page_label = st.selectbox("é æ•¸", options=page_options, index=st.session_state.page, label_visibility="collapsed")
                    if new_page_label != current_page_label:
                        st.session_state.page = page_options.index(new_page_label)
                        st.rerun()

                with next_button_col:
                     if st.session_state.page > 0:
                        st.button("â¬…ï¸ ä¸Šä¸€é ", on_click=lambda: st.session_state.update(page=st.session_state.page - 1), key="prev_page", use_container_width=True)
                     if st.session_state.page < total_pages - 1:
                        st.button("ä¸‹ä¸€é  â¡ï¸", on_click=lambda: st.session_state.update(page=st.session_state.page + 1), key="next_page", use_container_width=True)
except FileNotFoundError:
    st.error(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆ '{DATA_URL}'ã€‚")
    st.info("è«‹ç¢ºèªæ‚¨å·²å°‡æ­£ç¢ºçš„ Raw URL è²¼å…¥ç¨‹å¼ç¢¼ä¸­ã€‚")
except Exception as e:
    st.error(f"è™•ç†è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
